{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa29c335",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================================================================\n",
    "# Step 0: Install Dependencies\n",
    "# ==============================================================================\n",
    "# This notebook requires PyTorch Geometric and sentence-transformers.\n",
    "!pip install ipywidgets pandas torch_geometric matplotlib sentence-transformers -q\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import HGTConv, Linear\n",
    "from torch_geometric.data import HeteroData\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.manifold import TSNE\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "print(f\"PyTorch Version: {torch.__version__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2751e7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================================================================\n",
    "# Step 1: Generate the Temporal Network Data\n",
    "# ==============================================================================\n",
    "# We will create a network of 20 devices with a failure that spreads.\n",
    "\n",
    "NUM_NODES = 20\n",
    "NUM_TIMESTEPS = 15\n",
    "DEVICE_TYPES = ['router', 'switch', 'firewall']\n",
    "\n",
    "# Create a random graph structure\n",
    "G = nx.erdos_renyi_graph(NUM_NODES, p=0.2, seed=42)\n",
    "while not nx.is_connected(G):\n",
    "    G = nx.erdos_renyi_graph(NUM_NODES, p=0.2, seed=np.random.randint(1000))\n",
    "\n",
    "# Assign device types and initial states\n",
    "node_data = []\n",
    "for i in range(NUM_NODES):\n",
    "    node_data.append({\n",
    "        'id': i,\n",
    "        'type': np.random.choice(DEVICE_TYPES),\n",
    "        'status': 'normal'\n",
    "    })\n",
    "df_nodes = pd.DataFrame(node_data)\n",
    "\n",
    "# --- Simulate Failure Propagation ---\n",
    "# At T=5, a switch will fail. The failure will spread to its neighbors.\n",
    "FAILURE_START_TIME = 5\n",
    "PATIENT_ZERO_ID = df_nodes[df_nodes['type'] == 'switch'].id.iloc[0]\n",
    "\n",
    "temporal_snapshots = []\n",
    "\n",
    "for t in range(NUM_TIMESTEPS):\n",
    "    cpu_usage = []\n",
    "    mem_usage = []\n",
    "    status_text = []\n",
    "\n",
    "    # Update node states based on failure propagation\n",
    "    for i in range(NUM_NODES):\n",
    "        node = df_nodes.iloc[i]\n",
    "        current_status = node['status']\n",
    "\n",
    "        if node.id == PATIENT_ZERO_ID and t >= FAILURE_START_TIME:\n",
    "            df_nodes.at[i, 'status'] = 'failure'\n",
    "        elif current_status == 'failure':\n",
    "             # Keep it in failure state\n",
    "            pass\n",
    "        elif current_status == 'impacted':\n",
    "             # Keep it in impacted state\n",
    "            pass\n",
    "        else: # Normal state\n",
    "            neighbors = list(G.neighbors(i))\n",
    "            for neighbor_id in neighbors:\n",
    "                if df_nodes.iloc[neighbor_id]['status'] == 'failure' and t > FAILURE_START_TIME:\n",
    "                    df_nodes.at[i, 'status'] = 'impacted'\n",
    "                    break\n",
    "\n",
    "    # Generate features for the current timestep\n",
    "    for i in range(NUM_NODES):\n",
    "        status = df_nodes.iloc[i]['status']\n",
    "        if status == 'failure':\n",
    "            cpu = np.random.uniform(0.9, 1.0)\n",
    "            mem = np.random.uniform(0.7, 0.9)\n",
    "            text = \"CRITICAL: High CPU Load - Port Flapping\"\n",
    "        elif status == 'impacted':\n",
    "            cpu = np.random.uniform(0.6, 0.8)\n",
    "            mem = np.random.uniform(0.5, 0.7)\n",
    "            text = \"WARNING: High Latency Detected - Potential Congestion\"\n",
    "        else: # Normal\n",
    "            cpu = np.random.uniform(0.1, 0.3)\n",
    "            mem = np.random.uniform(0.2, 0.4)\n",
    "            text = \"INFO: Nominal Operation - BGP Session Active\"\n",
    "\n",
    "        cpu_usage.append(cpu)\n",
    "        mem_usage.append(mem)\n",
    "        status_text.append(text)\n",
    "\n",
    "    snapshot = {\n",
    "        'cpu': np.array(cpu_usage),\n",
    "        'mem': np.array(mem_usage),\n",
    "        'text': status_text,\n",
    "        'status': df_nodes['status'].copy().values\n",
    "    }\n",
    "    temporal_snapshots.append(snapshot)\n",
    "\n",
    "print(f\"Generated {len(temporal_snapshots)} temporal snapshots for {NUM_NODES} devices.\")\n",
    "print(f\"Failure introduced at T={FAILURE_START_TIME} on Node {PATIENT_ZERO_ID} (a {df_nodes.iloc[PATIENT_ZERO_ID]['type']}).\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d418c22f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================================================================\n",
    "# Step 1.5: Visualize the Demo Network Topology\n",
    "# ==============================================================================\n",
    "# Create a visual representation of the network graph with device types\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as mpatches\n",
    "\n",
    "# Create network visualization\n",
    "plt.figure(figsize=(14, 10))\n",
    "\n",
    "# Set up the layout with better spacing\n",
    "pos = nx.spring_layout(G, k=2, iterations=50, seed=42)\n",
    "\n",
    "# Define device type colors and shapes\n",
    "device_colors = {'router': '#FF6B6B', 'switch': '#4ECDC4', 'firewall': '#45B7D1'}\n",
    "device_shapes = {'router': 's', 'switch': 'o', 'firewall': '^'}  # square, circle, triangle\n",
    "device_sizes = {'router': 800, 'switch': 600, 'firewall': 700}\n",
    "\n",
    "# Draw edges first (so they appear behind nodes)\n",
    "nx.draw_networkx_edges(G, pos, edge_color='lightgray', width=2, alpha=0.6)\n",
    "\n",
    "# Draw nodes by device type\n",
    "for device_type in DEVICE_TYPES:\n",
    "    # Get nodes of this device type\n",
    "    nodes_of_type = df_nodes[df_nodes['type'] == device_type]['id'].tolist()\n",
    "    \n",
    "    if nodes_of_type:\n",
    "        # Draw nodes of this type\n",
    "        nx.draw_networkx_nodes(G, pos, \n",
    "                             nodelist=nodes_of_type,\n",
    "                             node_color=device_colors[device_type],\n",
    "                             node_shape=device_shapes[device_type],\n",
    "                             node_size=device_sizes[device_type],\n",
    "                             alpha=0.8,\n",
    "                             edgecolors='black',\n",
    "                             linewidths=2)\n",
    "\n",
    "# Highlight patient zero with special styling\n",
    "patient_zero_pos = pos[PATIENT_ZERO_ID]\n",
    "plt.scatter(patient_zero_pos[0], patient_zero_pos[1], \n",
    "           s=1000, c='red', marker='*', \n",
    "           edgecolors='darkred', linewidths=3,\n",
    "           alpha=0.9, zorder=10, label='Patient Zero')\n",
    "\n",
    "# Add node labels\n",
    "labels = {}\n",
    "for node_id in G.nodes():\n",
    "    device_type = df_nodes.iloc[node_id]['type']\n",
    "    # Create label with node ID and device type abbreviation\n",
    "    type_abbrev = {'router': 'R', 'switch': 'S', 'firewall': 'F'}[device_type]\n",
    "    labels[node_id] = f\"{node_id}\\n({type_abbrev})\"\n",
    "\n",
    "nx.draw_networkx_labels(G, pos, labels, font_size=8, font_weight='bold')\n",
    "\n",
    "# Create legend\n",
    "legend_elements = []\n",
    "for device_type in DEVICE_TYPES:\n",
    "    legend_elements.append(mpatches.Patch(color=device_colors[device_type], \n",
    "                                        label=f'{device_type.capitalize()} ({device_shapes[device_type]})'))\n",
    "\n",
    "# Add patient zero to legend\n",
    "legend_elements.append(plt.Line2D([0], [0], marker='*', color='w', \n",
    "                                markerfacecolor='red', markersize=15,\n",
    "                                label='Patient Zero (Failure Source)', \n",
    "                                markeredgecolor='darkred', markeredgewidth=2))\n",
    "\n",
    "plt.legend(handles=legend_elements, loc='upper left', bbox_to_anchor=(0.02, 0.98))\n",
    "\n",
    "plt.title('Demo Network Topology\\n20 Devices Connected via Erdős–Rényi Random Graph', \n",
    "         fontsize=16, fontweight='bold', pad=20)\n",
    "\n",
    "# Add network statistics\n",
    "stats_text = f\"\"\"Network Statistics:\n",
    "• Total Nodes: {NUM_NODES}\n",
    "• Total Edges: {G.number_of_edges()}\n",
    "• Average Degree: {2 * G.number_of_edges() / NUM_NODES:.1f}\n",
    "• Network Diameter: {nx.diameter(G) if nx.is_connected(G) else 'N/A'}\n",
    "• Clustering Coefficient: {nx.average_clustering(G):.3f}\n",
    "\n",
    "Device Distribution:\"\"\"\n",
    "\n",
    "for device_type in DEVICE_TYPES:\n",
    "    count = len(df_nodes[df_nodes['type'] == device_type])\n",
    "    stats_text += f\"\\n• {device_type.capitalize()}: {count} devices\"\n",
    "\n",
    "patient_zero_type = df_nodes.iloc[PATIENT_ZERO_ID]['type']\n",
    "stats_text += f\"\"\"\n",
    "\n",
    "Failure Simulation:\n",
    "• Patient Zero: Node {PATIENT_ZERO_ID} ({patient_zero_type})\n",
    "• Failure Start Time: T={FAILURE_START_TIME}\n",
    "• Total Simulation Time: {NUM_TIMESTEPS} timesteps\"\"\"\n",
    "\n",
    "plt.text(1.02, 0.98, stats_text, transform=plt.gca().transAxes, \n",
    "         fontsize=10, verticalalignment='top', \n",
    "         bbox=dict(boxstyle='round,pad=0.5', facecolor='lightblue', alpha=0.7))\n",
    "\n",
    "plt.axis('off')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Print adjacency information for patient zero\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(f\"PATIENT ZERO NETWORK ANALYSIS\")\n",
    "print(f\"{'='*60}\")\n",
    "print(f\"Patient Zero (Node {PATIENT_ZERO_ID}) is a {df_nodes.iloc[PATIENT_ZERO_ID]['type']}\")\n",
    "print(f\"Direct neighbors: {list(G.neighbors(PATIENT_ZERO_ID))}\")\n",
    "\n",
    "neighbor_types = []\n",
    "for neighbor in G.neighbors(PATIENT_ZERO_ID):\n",
    "    neighbor_type = df_nodes.iloc[neighbor]['type']\n",
    "    neighbor_types.append(neighbor_type)\n",
    "    print(f\"  - Node {neighbor}: {neighbor_type}\")\n",
    "\n",
    "print(f\"\\nNeighbor device types: {set(neighbor_types)}\")\n",
    "print(f\"Patient zero degree (connections): {G.degree(PATIENT_ZERO_ID)}\")\n",
    "\n",
    "# Show how failure will spread\n",
    "print(f\"\\nFailure Propagation Path:\")\n",
    "print(f\"T=0-{FAILURE_START_TIME-1}: All nodes normal\")\n",
    "print(f\"T={FAILURE_START_TIME}: Node {PATIENT_ZERO_ID} fails\")\n",
    "print(f\"T={FAILURE_START_TIME+1}+: Neighbors become 'impacted':\")\n",
    "for neighbor in G.neighbors(PATIENT_ZERO_ID):\n",
    "    print(f\"  - Node {neighbor} ({df_nodes.iloc[neighbor]['type']}) will show degraded performance\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea213144",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================================================================\n",
    "# Step 2: Feature Engineering with Sentence-Transformers\n",
    "# ==============================================================================\n",
    "# Convert text status messages into meaningful embeddings.\n",
    "\n",
    "@torch.no_grad()\n",
    "def embed_text_features(snapshots, model_name='all-MiniLM-L6-v2'):\n",
    "    model = SentenceTransformer(model_name)\n",
    "    all_texts = [text for snapshot in snapshots for text in snapshot['text']]\n",
    "    unique_texts = sorted(list(set(all_texts)))\n",
    "    embeddings = model.encode(unique_texts, convert_to_tensor=True, device='cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    text_to_embedding = {text: emb for text, emb in zip(unique_texts, embeddings)}\n",
    "\n",
    "    for snapshot in snapshots:\n",
    "        snapshot['text_embeddings'] = torch.stack([text_to_embedding[text] for text in snapshot['text']])\n",
    "    return snapshots\n",
    "\n",
    "temporal_snapshots = embed_text_features(temporal_snapshots)\n",
    "TEXT_EMBED_DIM = temporal_snapshots[0]['text_embeddings'].shape[1]\n",
    "print(f\"Text features embedded into vectors of size {TEXT_EMBED_DIM}.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc912006",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================================================================\n",
    "# Step 3: Create PyTorch Geometric HeteroData Objects\n",
    "# ==============================================================================\n",
    "# We convert our list of snapshots into a list of HeteroData objects.\n",
    "\n",
    "pyg_snapshots = []\n",
    "node_type_map = {i: df_nodes.iloc[i]['type'] for i in range(NUM_NODES)}\n",
    "\n",
    "for snapshot in temporal_snapshots:\n",
    "    data = HeteroData()\n",
    "\n",
    "    # Node features - separate by device type\n",
    "    for node_type in DEVICE_TYPES:\n",
    "        mask = (df_nodes['type'] == node_type).values\n",
    "        if mask.any():\n",
    "            numeric_feats = torch.tensor(np.vstack([snapshot['cpu'][mask], snapshot['mem'][mask]]).T, dtype=torch.float32)\n",
    "            text_feats = snapshot['text_embeddings'][mask]\n",
    "            data[node_type].x = torch.cat([numeric_feats, text_feats], dim=1)\n",
    "            data[node_type].node_ids = torch.tensor(df_nodes[mask].id.values) # Keep track of original IDs\n",
    "\n",
    "    # Edge index - we need to map node IDs to their positions within each node type\n",
    "    # Create a global node mapping\n",
    "    global_to_local = {}\n",
    "    local_to_global = {}\n",
    "    \n",
    "    for node_type in DEVICE_TYPES:\n",
    "        if node_type in data.node_types:\n",
    "            for local_idx, global_id in enumerate(data[node_type].node_ids):\n",
    "                global_to_local[int(global_id)] = (node_type, local_idx)\n",
    "                local_to_global[(node_type, local_idx)] = int(global_id)\n",
    "\n",
    "    # Create edges for each combination of node types\n",
    "    for src_type in DEVICE_TYPES:\n",
    "        for dst_type in DEVICE_TYPES:\n",
    "            if src_type in data.node_types and dst_type in data.node_types:\n",
    "                sources, targets = [], []\n",
    "                \n",
    "                for u, v in G.edges():\n",
    "                    # Add edge u->v\n",
    "                    if u in global_to_local and v in global_to_local:\n",
    "                        u_type, u_local = global_to_local[u]\n",
    "                        v_type, v_local = global_to_local[v]\n",
    "                        \n",
    "                        if u_type == src_type and v_type == dst_type:\n",
    "                            sources.append(u_local)\n",
    "                            targets.append(v_local)\n",
    "                    \n",
    "                    # Add edge v->u (bidirectional)\n",
    "                    if v in global_to_local and u in global_to_local:\n",
    "                        v_type, v_local = global_to_local[v]\n",
    "                        u_type, u_local = global_to_local[u]\n",
    "                        \n",
    "                        if v_type == src_type and u_type == dst_type:\n",
    "                            sources.append(v_local)\n",
    "                            targets.append(u_local)\n",
    "                \n",
    "                if sources and targets:\n",
    "                    edge_index = torch.tensor([sources, targets], dtype=torch.int64)\n",
    "                    data[src_type, 'connects_to', dst_type].edge_index = edge_index\n",
    "\n",
    "    # Store labels for our training task\n",
    "    data.y = torch.tensor(snapshot['cpu'], dtype=torch.float32)\n",
    "    data.status = snapshot['status'] # For visualization later\n",
    "\n",
    "    pyg_snapshots.append(data)\n",
    "\n",
    "print(f\"Created {len(pyg_snapshots)} PyG HeteroData snapshots.\")\n",
    "print(\"\\nExample snapshot at T=0:\")\n",
    "print(pyg_snapshots[0])\n",
    "print(f\"Node types in first snapshot: {pyg_snapshots[0].node_types}\")\n",
    "print(f\"Edge types in first snapshot: {pyg_snapshots[0].edge_types}\")\n",
    "\n",
    "# Print device type distribution\n",
    "for node_type in DEVICE_TYPES:\n",
    "    if node_type in pyg_snapshots[0].node_types:\n",
    "        print(f\"{node_type}: {pyg_snapshots[0][node_type].x.shape[0]} nodes\")\n",
    "    else:\n",
    "        print(f\"{node_type}: 0 nodes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a23052f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================================================================\n",
    "# Step 4: Define the Simplified THGAT Model\n",
    "# ==============================================================================\n",
    "\n",
    "class TemporalHGT(nn.Module):\n",
    "    def __init__(self, in_channels, hidden_channels, out_channels, node_types, metadata):\n",
    "        super().__init__()\n",
    "        self.hidden_channels = hidden_channels\n",
    "        self.node_types = node_types\n",
    "\n",
    "        # Spatial Layer: HGTConv to handle heterogeneity\n",
    "        self.hgt_conv = HGTConv(in_channels, hidden_channels, metadata, heads=2)\n",
    "        \n",
    "        # Temporal Layer: A GRU for each node type to learn temporal patterns\n",
    "        self.gru_dict = nn.ModuleDict({\n",
    "            node_type: nn.GRU(hidden_channels, hidden_channels, batch_first=True)\n",
    "            for node_type in node_types\n",
    "        })\n",
    "\n",
    "        # Output Layer: Predicts the next CPU value\n",
    "        self.out = Linear(hidden_channels, out_channels)\n",
    "\n",
    "    def forward(self, snapshot_sequence):\n",
    "        # Store embeddings over time for each node type\n",
    "        embeddings_over_time = {node_type: [] for node_type in self.node_types}\n",
    "        \n",
    "        for snapshot in snapshot_sequence:\n",
    "            # Get node features for each type\n",
    "            x_dict = {}\n",
    "            for node_type in self.node_types:\n",
    "                if node_type in snapshot.node_types:\n",
    "                    x_dict[node_type] = snapshot[node_type].x\n",
    "\n",
    "            # Get edge index dictionary\n",
    "            edge_index_dict = {}\n",
    "            for edge_type in snapshot.edge_types:\n",
    "                edge_index_dict[edge_type] = snapshot[edge_type].edge_index\n",
    "\n",
    "            # Spatial message passing\n",
    "            x_dict_out = self.hgt_conv(x_dict, edge_index_dict)\n",
    "            \n",
    "            # Store embeddings for each node type\n",
    "            for node_type, embeddings in x_dict_out.items():\n",
    "                embeddings_over_time[node_type].append(embeddings)\n",
    "        \n",
    "        # Apply temporal modeling for each node type\n",
    "        final_embeddings_by_type = {}\n",
    "        \n",
    "        for node_type in self.node_types:\n",
    "            if embeddings_over_time[node_type]:\n",
    "                # Stack embeddings over time: (num_nodes, seq_len, hidden_dim)\n",
    "                temporal_input = torch.stack(embeddings_over_time[node_type], dim=1)\n",
    "                num_nodes, seq_len, hidden_dim = temporal_input.shape\n",
    "                \n",
    "                # Apply GRU for this node type\n",
    "                # Reshape to (num_nodes, seq_len, hidden_dim) - already in correct format\n",
    "                gru_output, _ = self.gru_dict[node_type](temporal_input)\n",
    "                \n",
    "                # Use the final timestep output\n",
    "                final_embeddings_by_type[node_type] = gru_output[:, -1, :]  # (num_nodes, hidden_dim)\n",
    "        \n",
    "        # Combine all node type embeddings in original order\n",
    "        # We need to reconstruct the original node ordering\n",
    "        final_embeddings = []\n",
    "        node_type_positions = {}\n",
    "        \n",
    "        # Track position of each node type in the combined embedding\n",
    "        current_pos = 0\n",
    "        for node_type in self.node_types:\n",
    "            if node_type in final_embeddings_by_type:\n",
    "                node_type_positions[node_type] = (current_pos, current_pos + final_embeddings_by_type[node_type].shape[0])\n",
    "                current_pos += final_embeddings_by_type[node_type].shape[0]\n",
    "        \n",
    "        # Create a tensor to hold all embeddings in original node order\n",
    "        first_snapshot = snapshot_sequence[0]\n",
    "        total_nodes = sum(first_snapshot[nt].x.shape[0] for nt in first_snapshot.node_types)\n",
    "        combined_embeddings = torch.zeros(total_nodes, self.hidden_channels)\n",
    "        \n",
    "        # Fill in embeddings by reconstructing original order\n",
    "        global_idx = 0\n",
    "        for node_type in self.node_types:\n",
    "            if node_type in final_embeddings_by_type and node_type in first_snapshot.node_types:\n",
    "                num_nodes_of_type = final_embeddings_by_type[node_type].shape[0]\n",
    "                combined_embeddings[global_idx:global_idx + num_nodes_of_type] = final_embeddings_by_type[node_type]\n",
    "                global_idx += num_nodes_of_type\n",
    "        \n",
    "        # Prediction\n",
    "        pred = self.out(combined_embeddings).squeeze(-1)\n",
    "        return pred, combined_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "503c557e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================================================================\n",
    "# Step 5: Train the Model\n",
    "# ==============================================================================\n",
    "\n",
    "# Get the actual input feature dimensions from the data\n",
    "sample_snapshot = pyg_snapshots[0]\n",
    "actual_in_channels = None\n",
    "\n",
    "for node_type in sample_snapshot.node_types:\n",
    "    actual_in_channels = sample_snapshot[node_type].x.shape[1]\n",
    "    break\n",
    "\n",
    "print(f\"Actual input feature dimensions: {actual_in_channels}\")\n",
    "print(f\"This includes: 2 numeric features (CPU, memory) + {TEXT_EMBED_DIM} text embedding features\")\n",
    "\n",
    "# Model hyperparameters\n",
    "in_channels = actual_in_channels  # Use actual feature dimensions\n",
    "hidden_channels = 32\n",
    "out_channels = 1  # Predicting CPU usage\n",
    "num_epochs = 10\n",
    "learning_rate = 0.01\n",
    "T = 3  # Temporal window size\n",
    "\n",
    "# Get metadata from the first snapshot\n",
    "metadata = pyg_snapshots[0].metadata()\n",
    "node_types = list(metadata[0])  # Extract node types from metadata tuple\n",
    "\n",
    "print(f\"Node types in metadata: {node_types}\")\n",
    "print(f\"Edge types in metadata: {list(metadata[1])}\")\n",
    "\n",
    "# Initialize model\n",
    "model = TemporalHGT(in_channels, hidden_channels, out_channels, node_types, metadata)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "# Training loop\n",
    "model.train()\n",
    "for epoch in range(num_epochs):\n",
    "    total_loss = 0\n",
    "    num_sequences = 0\n",
    "    \n",
    "    # Each sequence of T snapshots\n",
    "    for i in range(len(pyg_snapshots) - T):\n",
    "        sequence = pyg_snapshots[i:i+T]\n",
    "        \n",
    "        # Forward pass\n",
    "        pred, embeddings = model(sequence)\n",
    "        \n",
    "        # Create target by getting next CPU values\n",
    "        # We'll predict the CPU usage at the next time step\n",
    "        next_snapshot_idx = i + T\n",
    "        next_snapshot = pyg_snapshots[next_snapshot_idx]\n",
    "        \n",
    "        # Collect CPU targets from all node types in original order\n",
    "        cpu_targets = []\n",
    "        for node_type in node_types:\n",
    "            if node_type in next_snapshot.node_types:\n",
    "                cpu_targets.append(next_snapshot[node_type].x[:, 0])  # CPU is first feature\n",
    "        \n",
    "        if cpu_targets:\n",
    "            target = torch.cat(cpu_targets, dim=0)\n",
    "            \n",
    "            # Ensure target and prediction have same size\n",
    "            min_size = min(pred.shape[0], target.shape[0])\n",
    "            pred_trimmed = pred[:min_size]\n",
    "            target_trimmed = target[:min_size]\n",
    "            \n",
    "            # Compute loss\n",
    "            loss = criterion(pred_trimmed, target_trimmed)\n",
    "            \n",
    "            # Backward pass\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            total_loss += loss.item()\n",
    "            num_sequences += 1\n",
    "    \n",
    "    avg_loss = total_loss / max(1, num_sequences)\n",
    "    print(f'Epoch {epoch+1}/{num_epochs}, Average Loss: {avg_loss:.4f}')\n",
    "\n",
    "print(\"Training completed!\")\n",
    "\n",
    "# Test the model on the last sequence\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    test_sequence = pyg_snapshots[-T:]\n",
    "    test_pred, test_embeddings = model(test_sequence)\n",
    "    print(f\"Test prediction shape: {test_pred.shape}\")\n",
    "    print(f\"Test embeddings shape: {test_embeddings.shape}\")\n",
    "    print(f\"Sample predictions: {test_pred[:5].cpu().numpy()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "900429b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================================================================\n",
    "# Step 6: Visualize Results with Device Type Preservation\n",
    "# ==============================================================================\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.manifold import TSNE\n",
    "import numpy as np\n",
    "\n",
    "# Get final embeddings from the trained model\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    final_sequence = pyg_snapshots[-T:]\n",
    "    _, final_embeddings = model(final_sequence)\n",
    "\n",
    "# Convert to numpy for visualization\n",
    "embeddings_np = final_embeddings.cpu().numpy()\n",
    "\n",
    "# Create device type labels for coloring\n",
    "device_labels = []\n",
    "device_colors = {'router': 'red', 'switch': 'blue', 'firewall': 'green'}\n",
    "color_list = []\n",
    "\n",
    "# Reconstruct device type mapping from the final snapshot\n",
    "final_snapshot = pyg_snapshots[-1]\n",
    "current_idx = 0\n",
    "\n",
    "for node_type in node_types:\n",
    "    if node_type in final_snapshot.node_types:\n",
    "        num_nodes_of_type = final_snapshot[node_type].x.shape[0]\n",
    "        device_labels.extend([node_type] * num_nodes_of_type)\n",
    "        color_list.extend([device_colors[node_type]] * num_nodes_of_type)\n",
    "        current_idx += num_nodes_of_type\n",
    "\n",
    "# Apply t-SNE for dimensionality reduction\n",
    "print(\"Applying t-SNE for visualization...\")\n",
    "tsne = TSNE(n_components=2, random_state=42, perplexity=min(30, len(embeddings_np)-1))\n",
    "embeddings_2d = tsne.fit_transform(embeddings_np)\n",
    "\n",
    "# Create visualization\n",
    "plt.figure(figsize=(12, 8))\n",
    "\n",
    "# Plot each device type separately for better legend\n",
    "for device_type, color in device_colors.items():\n",
    "    mask = np.array(device_labels) == device_type\n",
    "    if mask.any():\n",
    "        plt.scatter(embeddings_2d[mask, 0], embeddings_2d[mask, 1], \n",
    "                   c=color, label=f'{device_type.capitalize()} Devices', \n",
    "                   alpha=0.7, s=60)\n",
    "\n",
    "plt.title('Network Device Embeddings by Type\\n(Temporal Heterogeneous Graph Attention)', \n",
    "          fontsize=14, fontweight='bold')\n",
    "plt.xlabel('t-SNE Dimension 1')\n",
    "plt.ylabel('t-SNE Dimension 2')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "# Add text annotations for interesting points\n",
    "for i, (x, y) in enumerate(embeddings_2d):\n",
    "    if i % 10 == 0:  # Annotate every 10th point to avoid clutter\n",
    "        plt.annotate(f'Node {i}', (x, y), xytext=(5, 5), \n",
    "                    textcoords='offset points', fontsize=8, alpha=0.7)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Print summary statistics\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"NETWORK FAILURE ANALYSIS SUMMARY\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Total nodes analyzed: {len(embeddings_np)}\")\n",
    "print(f\"Device type distribution:\")\n",
    "for device_type in device_colors.keys():\n",
    "    count = device_labels.count(device_type)\n",
    "    print(f\"  - {device_type.capitalize()}: {count} devices\")\n",
    "\n",
    "print(f\"\\nModel architecture:\")\n",
    "print(f\"  - Input features: {in_channels}\")\n",
    "print(f\"  - Hidden dimensions: {hidden_channels}\")\n",
    "print(f\"  - Temporal window: {T} timesteps\")\n",
    "print(f\"  - Node types preserved: {len(node_types)}\")\n",
    "\n",
    "print(f\"\\nTraining completed with {num_epochs} epochs\")\n",
    "print(f\"Final embedding dimension: {embeddings_np.shape}\")\n",
    "\n",
    "# Analyze failure propagation patterns\n",
    "final_snapshot = pyg_snapshots[-1]\n",
    "print(f\"\\nFailure propagation analysis:\")\n",
    "print(f\"  - Patient zero was node {PATIENT_ZERO_ID}\")\n",
    "print(f\"  - Total simulation timesteps: {NUM_TIMESTEPS}\")\n",
    "print(f\"  - Failure started at timestep: {FAILURE_START_TIME}\")\n",
    "\n",
    "# Show CPU usage evolution for different device types\n",
    "print(f\"\\nDevice type performance patterns:\")\n",
    "current_idx = 0\n",
    "for node_type in node_types:\n",
    "    if node_type in final_snapshot.node_types:\n",
    "        num_nodes = final_snapshot[node_type].x.shape[0]\n",
    "        type_embeddings = embeddings_np[current_idx:current_idx + num_nodes]\n",
    "        avg_norm = np.mean(np.linalg.norm(type_embeddings, axis=1))\n",
    "        print(f\"  - {node_type.capitalize()}: Average embedding norm = {avg_norm:.3f}\")\n",
    "        current_idx += num_nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd8bb301",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================================================================\n",
    "# Step 6.5: Enhanced Clustering Analysis and Alternative Visualizations\n",
    "# ==============================================================================\n",
    "# Let's investigate why device type clustering isn't clear and try different approaches\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_score\n",
    "import numpy as np\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"ENHANCED CLUSTERING ANALYSIS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# First, let's analyze the embedding space directly\n",
    "print(\"1. Raw Embedding Space Analysis:\")\n",
    "print(f\"   Embedding shape: {embeddings_np.shape}\")\n",
    "print(f\"   Embedding range: [{np.min(embeddings_np):.4f}, {np.max(embeddings_np):.4f}]\")\n",
    "\n",
    "# Calculate inter-class vs intra-class distances\n",
    "device_type_means = {}\n",
    "device_type_stds = {}\n",
    "\n",
    "for device_type in ['router', 'switch', 'firewall']:\n",
    "    mask = np.array(device_labels) == device_type\n",
    "    if mask.any():\n",
    "        type_embeddings = embeddings_np[mask]\n",
    "        device_type_means[device_type] = np.mean(type_embeddings, axis=0)\n",
    "        device_type_stds[device_type] = np.std(type_embeddings, axis=0)\n",
    "        \n",
    "        # Intra-class distances\n",
    "        intra_distances = []\n",
    "        for i in range(len(type_embeddings)):\n",
    "            for j in range(i+1, len(type_embeddings)):\n",
    "                intra_distances.append(np.linalg.norm(type_embeddings[i] - type_embeddings[j]))\n",
    "        \n",
    "        print(f\"   {device_type.capitalize()}:\")\n",
    "        print(f\"     - Count: {mask.sum()}\")\n",
    "        print(f\"     - Mean embedding norm: {np.linalg.norm(device_type_means[device_type]):.4f}\")\n",
    "        print(f\"     - Average intra-class distance: {np.mean(intra_distances):.4f}\")\n",
    "\n",
    "# Inter-class distances\n",
    "print(\"\\n2. Inter-class Distances:\")\n",
    "device_types = ['router', 'switch', 'firewall']\n",
    "for i, type1 in enumerate(device_types):\n",
    "    for j, type2 in enumerate(device_types):\n",
    "        if i < j and type1 in device_type_means and type2 in device_type_means:\n",
    "            dist = np.linalg.norm(device_type_means[type1] - device_type_means[type2])\n",
    "            print(f\"   {type1} <-> {type2}: {dist:.4f}\")\n",
    "\n",
    "# Try different dimensionality reduction techniques\n",
    "fig, axes = plt.subplots(2, 3, figsize=(18, 12))\n",
    "\n",
    "# 1. PCA (preserves global structure)\n",
    "print(\"\\n3. Trying PCA for better global structure preservation...\")\n",
    "pca = PCA(n_components=2, random_state=42)\n",
    "embeddings_pca = pca.fit_transform(embeddings_np)\n",
    "\n",
    "axes[0, 0].set_title('PCA Visualization\\n(Preserves Global Variance)')\n",
    "for device_type, color in device_colors.items():\n",
    "    mask = np.array(device_labels) == device_type\n",
    "    if mask.any():\n",
    "        axes[0, 0].scatter(embeddings_pca[mask, 0], embeddings_pca[mask, 1], \n",
    "                          c=color, label=f'{device_type.capitalize()}', alpha=0.7, s=60)\n",
    "axes[0, 0].legend()\n",
    "axes[0, 0].grid(True, alpha=0.3)\n",
    "print(f\"   PCA explained variance ratio: {pca.explained_variance_ratio_}\")\n",
    "\n",
    "# 2. t-SNE with different perplexity\n",
    "print(\"\\n4. Trying different t-SNE parameters...\")\n",
    "perplexities = [5, 15, 50]\n",
    "for idx, perplexity in enumerate(perplexities):\n",
    "    if perplexity < len(embeddings_np):\n",
    "        tsne_alt = TSNE(n_components=2, random_state=42, perplexity=perplexity, \n",
    "                       learning_rate=200, max_iter=1000)\n",
    "        embeddings_tsne_alt = tsne_alt.fit_transform(embeddings_np)\n",
    "        \n",
    "        col_idx = idx + 1\n",
    "        axes[0, col_idx].set_title(f't-SNE (perplexity={perplexity})')\n",
    "        for device_type, color in device_colors.items():\n",
    "            mask = np.array(device_labels) == device_type\n",
    "            if mask.any():\n",
    "                axes[0, col_idx].scatter(embeddings_tsne_alt[mask, 0], embeddings_tsne_alt[mask, 1], \n",
    "                                        c=color, label=f'{device_type.capitalize()}', alpha=0.7, s=60)\n",
    "        axes[0, col_idx].legend()\n",
    "        axes[0, col_idx].grid(True, alpha=0.3)\n",
    "\n",
    "# 3. Analyze clustering quality with K-means\n",
    "print(\"\\n5. Clustering Quality Analysis:\")\n",
    "for n_clusters in [2, 3, 4]:\n",
    "    kmeans = KMeans(n_clusters=n_clusters, random_state=42)\n",
    "    cluster_labels = kmeans.fit_predict(embeddings_np)\n",
    "    silhouette_avg = silhouette_score(embeddings_np, cluster_labels)\n",
    "    print(f\"   K-means with {n_clusters} clusters - Silhouette Score: {silhouette_avg:.4f}\")\n",
    "\n",
    "# 4. Visualize K-means clustering\n",
    "kmeans_3 = KMeans(n_clusters=3, random_state=42)\n",
    "cluster_labels = kmeans_3.fit_predict(embeddings_np)\n",
    "\n",
    "axes[1, 0].set_title('K-means Clustering (k=3)')\n",
    "scatter = axes[1, 0].scatter(embeddings_2d[:, 0], embeddings_2d[:, 1], \n",
    "                            c=cluster_labels, cmap='viridis', alpha=0.7, s=60)\n",
    "axes[1, 0].grid(True, alpha=0.3)\n",
    "\n",
    "# 5. Create a confusion matrix between device types and clusters\n",
    "print(\"\\n6. Device Type vs Cluster Analysis:\")\n",
    "device_type_to_num = {'router': 0, 'switch': 1, 'firewall': 2}\n",
    "true_labels = [device_type_to_num[label] for label in device_labels]\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(true_labels, cluster_labels)\n",
    "print(\"   Confusion Matrix (rows=device_types, cols=clusters):\")\n",
    "print(\"   Device Types: router(0), switch(1), firewall(2)\")\n",
    "print(f\"   {cm}\")\n",
    "\n",
    "# 6. Feature importance analysis\n",
    "print(\"\\n7. Feature Importance Analysis:\")\n",
    "# Calculate variance across device types for each embedding dimension\n",
    "feature_variances = []\n",
    "for dim in range(embeddings_np.shape[1]):\n",
    "    type_means = []\n",
    "    for device_type in device_types:\n",
    "        mask = np.array(device_labels) == device_type\n",
    "        if mask.any():\n",
    "            type_means.append(np.mean(embeddings_np[mask, dim]))\n",
    "    if len(type_means) > 1:\n",
    "        feature_variances.append(np.var(type_means))\n",
    "    else:\n",
    "        feature_variances.append(0)\n",
    "\n",
    "top_discriminative_dims = np.argsort(feature_variances)[-10:][::-1]\n",
    "print(f\"   Top 10 most discriminative dimensions: {top_discriminative_dims}\")\n",
    "variances_list = [feature_variances[dim] for dim in top_discriminative_dims]\n",
    "print(f\"   Their variances: {[f'{var:.6f}' for var in variances_list]}\")\n",
    "\n",
    "# 7. Visualize using only top discriminative features\n",
    "if len(top_discriminative_dims) >= 2:\n",
    "    axes[1, 1].set_title('Top 2 Discriminative Dimensions')\n",
    "    for device_type, color in device_colors.items():\n",
    "        mask = np.array(device_labels) == device_type\n",
    "        if mask.any():\n",
    "            axes[1, 1].scatter(embeddings_np[mask, top_discriminative_dims[0]], \n",
    "                              embeddings_np[mask, top_discriminative_dims[1]], \n",
    "                              c=color, label=f'{device_type.capitalize()}', alpha=0.7, s=60)\n",
    "    axes[1, 1].set_xlabel(f'Dimension {top_discriminative_dims[0]}')\n",
    "    axes[1, 1].set_ylabel(f'Dimension {top_discriminative_dims[1]}')\n",
    "    axes[1, 1].legend()\n",
    "    axes[1, 1].grid(True, alpha=0.3)\n",
    "\n",
    "# 8. Try UMAP if available\n",
    "try:\n",
    "    import umap\n",
    "    print(\"\\n8. Trying UMAP for better local structure preservation...\")\n",
    "    reducer = umap.UMAP(n_components=2, random_state=42, n_neighbors=15, min_dist=0.1)\n",
    "    embeddings_umap = reducer.fit_transform(embeddings_np)\n",
    "    \n",
    "    axes[1, 2].set_title('UMAP Visualization')\n",
    "    for device_type, color in device_colors.items():\n",
    "        mask = np.array(device_labels) == device_type\n",
    "        if mask.any():\n",
    "            axes[1, 2].scatter(embeddings_umap[mask, 0], embeddings_umap[mask, 1], \n",
    "                              c=color, label=f'{device_type.capitalize()}', alpha=0.7, s=60)\n",
    "    axes[1, 2].legend()\n",
    "    axes[1, 2].grid(True, alpha=0.3)\n",
    "except ImportError:\n",
    "    print(\"\\n8. UMAP not available (pip install umap-learn to try)\")\n",
    "    axes[1, 2].text(0.5, 0.5, 'UMAP not available\\npip install umap-learn', \n",
    "                    ha='center', va='center', transform=axes[1, 2].transAxes)\n",
    "    axes[1, 2].set_title('UMAP (Not Available)')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Summary and recommendations\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"CLUSTERING ANALYSIS SUMMARY\")\n",
    "print(\"=\"*80)\n",
    "print(\"Possible reasons for poor device type clustering:\")\n",
    "print(\"1. Model may be learning temporal patterns rather than device-type patterns\")\n",
    "print(\"2. All devices see similar failure propagation, reducing type-specific signatures\")\n",
    "print(\"3. Text embeddings may dominate over device-type specific features\")\n",
    "print(\"4. Network topology may be more important than device type for this task\")\n",
    "print(\"\\nRecommendations:\")\n",
    "print(\"- Try training with device-type specific objectives\")\n",
    "print(\"- Add device-type classification as an auxiliary task\")\n",
    "print(\"- Experiment with different loss functions that encourage type separation\")\n",
    "print(\"- Consider using device type as an explicit feature rather than just for heterogeneous processing\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef692582",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================================================================\n",
    "# Step 6.6: Retrain Model with Device Type Separation Objective\n",
    "# ==============================================================================\n",
    "# Add a contrastive loss to encourage device type clustering\n",
    "\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class ImprovedTemporalHGT(nn.Module):\n",
    "    def __init__(self, in_channels, hidden_channels, out_channels, node_types, metadata):\n",
    "        super().__init__()\n",
    "        self.hidden_channels = hidden_channels\n",
    "        self.node_types = node_types\n",
    "\n",
    "        # Spatial Layer: HGTConv to handle heterogeneity\n",
    "        self.hgt_conv = HGTConv(in_channels, hidden_channels, metadata, heads=2)\n",
    "        \n",
    "        # Temporal Layer: A GRU for each node type to learn temporal patterns\n",
    "        self.gru_dict = nn.ModuleDict({\n",
    "            node_type: nn.GRU(hidden_channels, hidden_channels, batch_first=True)\n",
    "            for node_type in node_types\n",
    "        })\n",
    "\n",
    "        # Output Layers\n",
    "        self.out = Linear(hidden_channels, out_channels)  # CPU prediction\n",
    "        self.device_classifier = Linear(hidden_channels, len(node_types))  # Device type classification\n",
    "\n",
    "    def forward(self, snapshot_sequence):\n",
    "        # Same forward pass as before\n",
    "        embeddings_over_time = {node_type: [] for node_type in self.node_types}\n",
    "        \n",
    "        for snapshot in snapshot_sequence:\n",
    "            x_dict = {}\n",
    "            for node_type in self.node_types:\n",
    "                if node_type in snapshot.node_types:\n",
    "                    x_dict[node_type] = snapshot[node_type].x\n",
    "\n",
    "            edge_index_dict = {}\n",
    "            for edge_type in snapshot.edge_types:\n",
    "                edge_index_dict[edge_type] = snapshot[edge_type].edge_index\n",
    "\n",
    "            x_dict_out = self.hgt_conv(x_dict, edge_index_dict)\n",
    "            \n",
    "            for node_type, embeddings in x_dict_out.items():\n",
    "                embeddings_over_time[node_type].append(embeddings)\n",
    "        \n",
    "        final_embeddings_by_type = {}\n",
    "        \n",
    "        for node_type in self.node_types:\n",
    "            if embeddings_over_time[node_type]:\n",
    "                temporal_input = torch.stack(embeddings_over_time[node_type], dim=1)\n",
    "                gru_output, _ = self.gru_dict[node_type](temporal_input)\n",
    "                final_embeddings_by_type[node_type] = gru_output[:, -1, :]\n",
    "        \n",
    "        # Combine embeddings in original order\n",
    "        first_snapshot = snapshot_sequence[0]\n",
    "        total_nodes = sum(first_snapshot[nt].x.shape[0] for nt in first_snapshot.node_types)\n",
    "        combined_embeddings = torch.zeros(total_nodes, self.hidden_channels)\n",
    "        \n",
    "        global_idx = 0\n",
    "        for node_type in self.node_types:\n",
    "            if node_type in final_embeddings_by_type and node_type in first_snapshot.node_types:\n",
    "                num_nodes_of_type = final_embeddings_by_type[node_type].shape[0]\n",
    "                combined_embeddings[global_idx:global_idx + num_nodes_of_type] = final_embeddings_by_type[node_type]\n",
    "                global_idx += num_nodes_of_type\n",
    "        \n",
    "        # Predictions\n",
    "        cpu_pred = self.out(combined_embeddings).squeeze(-1)\n",
    "        device_type_logits = self.device_classifier(combined_embeddings)\n",
    "        \n",
    "        return cpu_pred, combined_embeddings, device_type_logits\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"RETRAINING WITH DEVICE TYPE SEPARATION\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Create device type labels\n",
    "device_type_to_idx = {'router': 0, 'switch': 1, 'firewall': 2}\n",
    "device_type_labels_tensor = torch.tensor([device_type_to_idx[label] for label in device_labels])\n",
    "\n",
    "# Initialize improved model\n",
    "improved_model = ImprovedTemporalHGT(in_channels, hidden_channels, out_channels, node_types, metadata)\n",
    "improved_optimizer = torch.optim.Adam(improved_model.parameters(), lr=learning_rate)\n",
    "cpu_criterion = nn.MSELoss()\n",
    "device_criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "print(\"Training improved model with multi-task objectives...\")\n",
    "\n",
    "# Training loop with multi-task loss\n",
    "improved_model.train()\n",
    "for epoch in range(15):  # More epochs for better convergence\n",
    "    total_cpu_loss = 0\n",
    "    total_device_loss = 0\n",
    "    total_combined_loss = 0\n",
    "    num_sequences = 0\n",
    "    \n",
    "    for i in range(len(pyg_snapshots) - T):\n",
    "        sequence = pyg_snapshots[i:i+T]\n",
    "        \n",
    "        # Forward pass\n",
    "        cpu_pred, embeddings, device_logits = improved_model(sequence)\n",
    "        \n",
    "        # CPU prediction loss\n",
    "        next_snapshot_idx = i + T\n",
    "        next_snapshot = pyg_snapshots[next_snapshot_idx]\n",
    "        \n",
    "        cpu_targets = []\n",
    "        for node_type in node_types:\n",
    "            if node_type in next_snapshot.node_types:\n",
    "                cpu_targets.append(next_snapshot[node_type].x[:, 0])\n",
    "        \n",
    "        if cpu_targets:\n",
    "            cpu_target = torch.cat(cpu_targets, dim=0)\n",
    "            min_size = min(cpu_pred.shape[0], cpu_target.shape[0])\n",
    "            \n",
    "            cpu_loss = cpu_criterion(cpu_pred[:min_size], cpu_target[:min_size])\n",
    "            device_loss = device_criterion(device_logits[:min_size], device_type_labels_tensor[:min_size])\n",
    "            \n",
    "            # Combined loss with weighting\n",
    "            combined_loss = cpu_loss + 0.5 * device_loss  # Weight device classification\n",
    "            \n",
    "            improved_optimizer.zero_grad()\n",
    "            combined_loss.backward()\n",
    "            improved_optimizer.step()\n",
    "            \n",
    "            total_cpu_loss += cpu_loss.item()\n",
    "            total_device_loss += device_loss.item()\n",
    "            total_combined_loss += combined_loss.item()\n",
    "            num_sequences += 1\n",
    "    \n",
    "    if num_sequences > 0:\n",
    "        avg_cpu_loss = total_cpu_loss / num_sequences\n",
    "        avg_device_loss = total_device_loss / num_sequences\n",
    "        avg_combined_loss = total_combined_loss / num_sequences\n",
    "        \n",
    "        print(f'Epoch {epoch+1}/15: CPU Loss: {avg_cpu_loss:.4f}, '\n",
    "              f'Device Loss: {avg_device_loss:.4f}, Combined: {avg_combined_loss:.4f}')\n",
    "\n",
    "print(\"\\nImproved training completed!\")\n",
    "\n",
    "# Get new embeddings\n",
    "improved_model.eval()\n",
    "with torch.no_grad():\n",
    "    final_sequence = pyg_snapshots[-T:]\n",
    "    _, improved_embeddings, improved_device_logits = improved_model(final_sequence)\n",
    "\n",
    "improved_embeddings_np = improved_embeddings.cpu().numpy()\n",
    "\n",
    "# Evaluate device type classification accuracy\n",
    "device_predictions = torch.argmax(improved_device_logits, dim=1)\n",
    "device_accuracy = (device_predictions == device_type_labels_tensor).float().mean()\n",
    "print(f\"\\nDevice type classification accuracy: {device_accuracy:.3f}\")\n",
    "\n",
    "# Visualize improved embeddings\n",
    "fig, axes = plt.subplots(1, 3, figsize=(18, 6))\n",
    "\n",
    "# Original embeddings\n",
    "tsne_orig = TSNE(n_components=2, random_state=42, perplexity=min(15, len(embeddings_np)-1))\n",
    "embeddings_2d_orig = tsne_orig.fit_transform(embeddings_np)\n",
    "\n",
    "axes[0].set_title('Original Model Embeddings')\n",
    "for device_type, color in device_colors.items():\n",
    "    mask = np.array(device_labels) == device_type\n",
    "    if mask.any():\n",
    "        axes[0].scatter(embeddings_2d_orig[mask, 0], embeddings_2d_orig[mask, 1], \n",
    "                       c=color, label=f'{device_type.capitalize()}', alpha=0.7, s=60)\n",
    "axes[0].legend()\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# Improved embeddings\n",
    "tsne_improved = TSNE(n_components=2, random_state=42, perplexity=min(15, len(improved_embeddings_np)-1))\n",
    "embeddings_2d_improved = tsne_improved.fit_transform(improved_embeddings_np)\n",
    "\n",
    "axes[1].set_title('Improved Model Embeddings\\n(with Device Type Objective)')\n",
    "for device_type, color in device_colors.items():\n",
    "    mask = np.array(device_labels) == device_type\n",
    "    if mask.any():\n",
    "        axes[1].scatter(embeddings_2d_improved[mask, 0], embeddings_2d_improved[mask, 1], \n",
    "                       c=color, label=f'{device_type.capitalize()}', alpha=0.7, s=60)\n",
    "axes[1].legend()\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "# PCA comparison\n",
    "pca_improved = PCA(n_components=2, random_state=42)\n",
    "embeddings_pca_improved = pca_improved.fit_transform(improved_embeddings_np)\n",
    "\n",
    "axes[2].set_title('Improved Model PCA')\n",
    "for device_type, color in device_colors.items():\n",
    "    mask = np.array(device_labels) == device_type\n",
    "    if mask.any():\n",
    "        axes[2].scatter(embeddings_pca_improved[mask, 0], embeddings_pca_improved[mask, 1], \n",
    "                       c=color, label=f'{device_type.capitalize()}', alpha=0.7, s=60)\n",
    "axes[2].legend()\n",
    "axes[2].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Compare clustering quality\n",
    "from sklearn.metrics import adjusted_rand_score\n",
    "kmeans_improved = KMeans(n_clusters=3, random_state=42)\n",
    "improved_clusters = kmeans_improved.fit_predict(improved_embeddings_np)\n",
    "improved_silhouette = silhouette_score(improved_embeddings_np, improved_clusters)\n",
    "\n",
    "print(f\"\\nClustering Quality Comparison:\")\n",
    "print(f\"Original model silhouette score: {silhouette_score(embeddings_np, KMeans(n_clusters=3, random_state=42).fit_predict(embeddings_np)):.4f}\")\n",
    "print(f\"Improved model silhouette score: {improved_silhouette:.4f}\")\n",
    "\n",
    "# Device type vs cluster alignment\n",
    "improved_ari = adjusted_rand_score(true_labels, improved_clusters)\n",
    "original_ari = adjusted_rand_score(true_labels, KMeans(n_clusters=3, random_state=42).fit_predict(embeddings_np))\n",
    "\n",
    "print(f\"\\nDevice Type - Cluster Alignment (Adjusted Rand Index):\")\n",
    "print(f\"Original model ARI: {original_ari:.4f}\")\n",
    "print(f\"Improved model ARI: {improved_ari:.4f}\")\n",
    "print(\"(Higher ARI = better alignment between device types and clusters)\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d8ec8df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================================================================\n",
    "# Step 7: Analyze Failed Node Deviation from Average Embedding\n",
    "# ==============================================================================\n",
    "\n",
    "import numpy as np\n",
    "from scipy.spatial.distance import euclidean, cosine\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"FAILED NODE EMBEDDING ANALYSIS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Find the patient zero node in the final embeddings\n",
    "# We need to map from global node ID to the position in the final embeddings\n",
    "patient_zero_embedding_idx = None\n",
    "current_idx = 0\n",
    "\n",
    "# Reconstruct the node order to find patient zero's position\n",
    "for node_type in node_types:\n",
    "    if node_type in final_snapshot.node_types:\n",
    "        # Get the node IDs for this device type\n",
    "        node_ids = final_snapshot[node_type].node_ids\n",
    "        num_nodes_of_type = len(node_ids)\n",
    "        \n",
    "        # Check if patient zero is in this device type\n",
    "        for local_idx, global_id in enumerate(node_ids):\n",
    "            if global_id.item() == PATIENT_ZERO_ID:\n",
    "                patient_zero_embedding_idx = current_idx + local_idx\n",
    "                patient_zero_type = node_type\n",
    "                break\n",
    "        \n",
    "        current_idx += num_nodes_of_type\n",
    "        if patient_zero_embedding_idx is not None:\n",
    "            break\n",
    "\n",
    "print(f\"Patient Zero Analysis:\")\n",
    "print(f\"  - Node ID: {PATIENT_ZERO_ID}\")\n",
    "print(f\"  - Device Type: {patient_zero_type}\")\n",
    "print(f\"  - Position in embeddings: {patient_zero_embedding_idx}\")\n",
    "\n",
    "if patient_zero_embedding_idx is not None:\n",
    "    # Get the patient zero embedding\n",
    "    patient_zero_emb = embeddings_np[patient_zero_embedding_idx]\n",
    "    \n",
    "    # Calculate statistics for all nodes\n",
    "    all_embeddings_mean = np.mean(embeddings_np, axis=0)\n",
    "    all_embeddings_std = np.std(embeddings_np, axis=0)\n",
    "    \n",
    "    # Calculate statistics for same device type\n",
    "    same_type_mask = np.array(device_labels) == patient_zero_type\n",
    "    same_type_embeddings = embeddings_np[same_type_mask]\n",
    "    same_type_mean = np.mean(same_type_embeddings, axis=0)\n",
    "    same_type_std = np.std(same_type_embeddings, axis=0)\n",
    "    \n",
    "    # Calculate deviations\n",
    "    deviation_from_all = patient_zero_emb - all_embeddings_mean\n",
    "    deviation_from_same_type = patient_zero_emb - same_type_mean\n",
    "    \n",
    "    # Calculate distances\n",
    "    euclidean_dist_all = euclidean(patient_zero_emb, all_embeddings_mean)\n",
    "    euclidean_dist_same_type = euclidean(patient_zero_emb, same_type_mean)\n",
    "    cosine_dist_all = cosine(patient_zero_emb, all_embeddings_mean)\n",
    "    cosine_dist_same_type = cosine(patient_zero_emb, same_type_mean)\n",
    "    \n",
    "    # Calculate z-scores (how many standard deviations away)\n",
    "    z_scores_all = np.abs(deviation_from_all) / (all_embeddings_std + 1e-8)\n",
    "    z_scores_same_type = np.abs(deviation_from_same_type) / (same_type_std + 1e-8)\n",
    "    \n",
    "    print(f\"\\nDistance Analysis:\")\n",
    "    print(f\"  Euclidean distance from all nodes average: {euclidean_dist_all:.4f}\")\n",
    "    print(f\"  Euclidean distance from same type average: {euclidean_dist_same_type:.4f}\")\n",
    "    print(f\"  Cosine distance from all nodes average: {cosine_dist_all:.4f}\")\n",
    "    print(f\"  Cosine distance from same type average: {cosine_dist_same_type:.4f}\")\n",
    "    \n",
    "    print(f\"\\nDeviation Analysis:\")\n",
    "    print(f\"  Max absolute deviation from all nodes: {np.max(np.abs(deviation_from_all)):.4f}\")\n",
    "    print(f\"  Max absolute deviation from same type: {np.max(np.abs(deviation_from_same_type)):.4f}\")\n",
    "    print(f\"  Average z-score vs all nodes: {np.mean(z_scores_all):.4f}\")\n",
    "    print(f\"  Average z-score vs same type: {np.mean(z_scores_same_type):.4f}\")\n",
    "    print(f\"  Max z-score vs all nodes: {np.max(z_scores_all):.4f}\")\n",
    "    print(f\"  Max z-score vs same type: {np.max(z_scores_same_type):.4f}\")\n",
    "    \n",
    "    # Find dimensions with highest deviations\n",
    "    top_deviating_dims_all = np.argsort(np.abs(deviation_from_all))[-5:][::-1]\n",
    "    top_deviating_dims_same = np.argsort(np.abs(deviation_from_same_type))[-5:][::-1]\n",
    "    \n",
    "    print(f\"\\nTop 5 dimensions with highest deviation from all nodes:\")\n",
    "    for i, dim in enumerate(top_deviating_dims_all):\n",
    "        print(f\"  {i+1}. Dimension {dim}: deviation = {deviation_from_all[dim]:.4f}, z-score = {z_scores_all[dim]:.4f}\")\n",
    "    \n",
    "    print(f\"\\nTop 5 dimensions with highest deviation from same device type:\")\n",
    "    for i, dim in enumerate(top_deviating_dims_same):\n",
    "        print(f\"  {i+1}. Dimension {dim}: deviation = {deviation_from_same_type[dim]:.4f}, z-score = {z_scores_same_type[dim]:.4f}\")\n",
    "    \n",
    "    # Visualization of deviations\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "    \n",
    "    # Plot 1: Embedding magnitude comparison\n",
    "    axes[0, 0].bar(['Patient Zero', 'All Avg', 'Same Type Avg'], \n",
    "                   [np.linalg.norm(patient_zero_emb), \n",
    "                    np.linalg.norm(all_embeddings_mean), \n",
    "                    np.linalg.norm(same_type_mean)],\n",
    "                   color=['red', 'blue', 'green'])\n",
    "    axes[0, 0].set_title('Embedding Vector Magnitudes')\n",
    "    axes[0, 0].set_ylabel('L2 Norm')\n",
    "    \n",
    "    # Plot 2: Distribution of z-scores vs all nodes\n",
    "    axes[0, 1].hist(z_scores_all, bins=20, alpha=0.7, color='blue', edgecolor='black')\n",
    "    axes[0, 1].axvline(np.mean(z_scores_all), color='red', linestyle='--', \n",
    "                       label=f'Mean: {np.mean(z_scores_all):.2f}')\n",
    "    axes[0, 1].set_title('Z-Scores vs All Nodes Average')\n",
    "    axes[0, 1].set_xlabel('Z-Score')\n",
    "    axes[0, 1].set_ylabel('Frequency')\n",
    "    axes[0, 1].legend()\n",
    "    \n",
    "    # Plot 3: Distribution of z-scores vs same type\n",
    "    axes[1, 0].hist(z_scores_same_type, bins=20, alpha=0.7, color='green', edgecolor='black')\n",
    "    axes[1, 0].axvline(np.mean(z_scores_same_type), color='red', linestyle='--', \n",
    "                       label=f'Mean: {np.mean(z_scores_same_type):.2f}')\n",
    "    axes[1, 0].set_title('Z-Scores vs Same Device Type Average')\n",
    "    axes[1, 0].set_xlabel('Z-Score')\n",
    "    axes[1, 0].set_ylabel('Frequency')\n",
    "    axes[1, 0].legend()\n",
    "    \n",
    "    # Plot 4: Top deviating dimensions\n",
    "    top_dims = top_deviating_dims_all[:10]  # Top 10 for visibility\n",
    "    axes[1, 1].bar(range(len(top_dims)), [np.abs(deviation_from_all[dim]) for dim in top_dims])\n",
    "    axes[1, 1].set_title('Top 10 Deviating Dimensions (vs All Nodes)')\n",
    "    axes[1, 1].set_xlabel('Dimension Rank')\n",
    "    axes[1, 1].set_ylabel('Absolute Deviation')\n",
    "    axes[1, 1].set_xticks(range(len(top_dims)))\n",
    "    axes[1, 1].set_xticklabels([f'D{dim}' for dim in top_dims], rotation=45)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Comparison with other nodes of same type\n",
    "    print(f\"\\nComparison with other {patient_zero_type} devices:\")\n",
    "    same_type_indices = np.where(same_type_mask)[0]\n",
    "    same_type_distances = []\n",
    "    \n",
    "    for idx in same_type_indices:\n",
    "        if idx != patient_zero_embedding_idx:\n",
    "            dist = euclidean(patient_zero_emb, embeddings_np[idx])\n",
    "            same_type_distances.append(dist)\n",
    "    \n",
    "    if same_type_distances:\n",
    "        print(f\"  Average distance to other {patient_zero_type}s: {np.mean(same_type_distances):.4f}\")\n",
    "        print(f\"  Min distance to other {patient_zero_type}s: {np.min(same_type_distances):.4f}\")\n",
    "        print(f\"  Max distance to other {patient_zero_type}s: {np.max(same_type_distances):.4f}\")\n",
    "        \n",
    "        # Rank among same type devices\n",
    "        all_same_type_dists = [euclidean(same_type_mean, embeddings_np[idx]) for idx in same_type_indices]\n",
    "        patient_zero_dist_rank = sorted(all_same_type_dists, reverse=True).index(\n",
    "            euclidean(same_type_mean, patient_zero_emb)) + 1\n",
    "        print(f\"  Patient zero ranks #{patient_zero_dist_rank} out of {len(same_type_indices)} {patient_zero_type} devices\")\n",
    "        print(f\"  (1 = most deviant from type average)\")\n",
    "\n",
    "else:\n",
    "    print(\"Error: Could not find patient zero in the embeddings!\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a654bad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================================================================\n",
    "# Patient Zero Dimensional Comparison Visualization\n",
    "# ==============================================================================\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"PATIENT ZERO DIMENSIONAL COMPARISON\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Get patient zero information\n",
    "patient_zero_emb = embeddings_np[patient_zero_embedding_idx]\n",
    "same_type_embeddings = embeddings_np[same_type_mask]\n",
    "all_embeddings = embeddings_np\n",
    "\n",
    "# Create comprehensive visualization\n",
    "fig = plt.figure(figsize=(20, 16))\n",
    "\n",
    "# 1. Radar Chart - Top Discriminative Dimensions\n",
    "ax1 = plt.subplot(3, 3, 1, projection='polar')\n",
    "top_dims_subset = top_discriminative_dims[:8]  # Use top 8 for cleaner visualization\n",
    "angles = np.linspace(0, 2*np.pi, len(top_dims_subset), endpoint=False)\n",
    "\n",
    "# Normalize values to [0, 1] for radar chart\n",
    "patient_zero_values = patient_zero_emb[top_dims_subset]\n",
    "same_type_mean_values = same_type_mean[top_dims_subset]\n",
    "all_mean_values = all_embeddings_mean[top_dims_subset]\n",
    "\n",
    "# Normalize to 0-1 range\n",
    "all_values = np.concatenate([patient_zero_values, same_type_mean_values, all_mean_values])\n",
    "min_val, max_val = np.min(all_values), np.max(all_values)\n",
    "if max_val != min_val:\n",
    "    patient_zero_norm = (patient_zero_values - min_val) / (max_val - min_val)\n",
    "    same_type_norm = (same_type_mean_values - min_val) / (max_val - min_val)\n",
    "    all_mean_norm = (all_mean_values - min_val) / (max_val - min_val)\n",
    "else:\n",
    "    patient_zero_norm = np.ones_like(patient_zero_values) * 0.5\n",
    "    same_type_norm = np.ones_like(same_type_mean_values) * 0.5\n",
    "    all_mean_norm = np.ones_like(all_mean_values) * 0.5\n",
    "\n",
    "ax1.plot(angles, patient_zero_norm, 'r-', linewidth=3, label='Patient Zero', marker='o')\n",
    "ax1.plot(angles, same_type_norm, 'g--', linewidth=2, label='Switch Average', marker='s')\n",
    "ax1.plot(angles, all_mean_norm, 'b:', linewidth=2, label='All Nodes Average', marker='^')\n",
    "ax1.fill(angles, patient_zero_norm, 'red', alpha=0.2)\n",
    "ax1.set_ylim(0, 1)\n",
    "ax1.set_title('Top Discriminative Dimensions\\n(Radar Chart)', pad=20)\n",
    "ax1.legend(loc='upper right', bbox_to_anchor=(1.3, 1.1))\n",
    "\n",
    "# Set dimension labels\n",
    "dim_labels = [f'Dim {dim}' for dim in top_dims_subset]\n",
    "ax1.set_thetagrids(angles * 180/np.pi, dim_labels)\n",
    "\n",
    "# 2. Dimensional Deviation Bar Chart\n",
    "ax2 = plt.subplot(3, 3, 2)\n",
    "top_10_dims = top_deviating_dims_all[:10]\n",
    "deviations = np.abs(patient_zero_emb[top_10_dims] - all_embeddings_mean[top_10_dims])\n",
    "colors = ['red' if dev > 2*all_embeddings_std[dim] else 'orange' if dev > all_embeddings_std[dim] else 'yellow' \n",
    "          for dev, dim in zip(deviations, top_10_dims)]\n",
    "\n",
    "bars = ax2.bar(range(len(top_10_dims)), deviations, color=colors, alpha=0.7)\n",
    "ax2.set_xlabel('Top Deviating Dimensions')\n",
    "ax2.set_ylabel('Absolute Deviation')\n",
    "ax2.set_title('Patient Zero Deviations\\n(vs All Nodes Mean)')\n",
    "ax2.set_xticks(range(len(top_10_dims)))\n",
    "ax2.set_xticklabels([f'D{dim}' for dim in top_10_dims], rotation=45)\n",
    "\n",
    "# Add value labels on bars\n",
    "for bar, dev in zip(bars, deviations):\n",
    "    height = bar.get_height()\n",
    "    ax2.text(bar.get_x() + bar.get_width()/2., height + 0.01,\n",
    "             f'{dev:.3f}', ha='center', va='bottom', fontsize=8)\n",
    "\n",
    "# 3. 3D Scatter Plot - Top 3 Discriminative Dimensions\n",
    "ax3 = plt.subplot(3, 3, 3, projection='3d')\n",
    "top_3_dims = top_discriminative_dims[:3]\n",
    "\n",
    "# All nodes of same type (switches)\n",
    "switch_embeddings = embeddings_np[same_type_mask]\n",
    "ax3.scatter(switch_embeddings[:, top_3_dims[0]], \n",
    "           switch_embeddings[:, top_3_dims[1]], \n",
    "           switch_embeddings[:, top_3_dims[2]], \n",
    "           c='lightblue', alpha=0.6, s=60, label='Other Switches')\n",
    "\n",
    "# Patient zero\n",
    "ax3.scatter(patient_zero_emb[top_3_dims[0]], \n",
    "           patient_zero_emb[top_3_dims[1]], \n",
    "           patient_zero_emb[top_3_dims[2]], \n",
    "           c='red', s=200, marker='*', label='Patient Zero', edgecolors='black')\n",
    "\n",
    "# Switch type mean\n",
    "ax3.scatter(same_type_mean[top_3_dims[0]], \n",
    "           same_type_mean[top_3_dims[1]], \n",
    "           same_type_mean[top_3_dims[2]], \n",
    "           c='green', s=150, marker='s', label='Switch Mean', edgecolors='black')\n",
    "\n",
    "ax3.set_xlabel(f'Dimension {top_3_dims[0]}')\n",
    "ax3.set_ylabel(f'Dimension {top_3_dims[1]}')\n",
    "ax3.set_zlabel(f'Dimension {top_3_dims[2]}')\n",
    "ax3.set_title('3D View: Top 3 Discriminative Dims')\n",
    "ax3.legend()\n",
    "\n",
    "# 4. Distance Heatmap\n",
    "ax4 = plt.subplot(3, 3, 4)\n",
    "switch_indices = np.where(same_type_mask)[0]\n",
    "n_switches = len(switch_indices)\n",
    "\n",
    "# Calculate pairwise distances between all switches\n",
    "distance_matrix = np.zeros((n_switches, n_switches))\n",
    "for i in range(n_switches):\n",
    "    for j in range(n_switches):\n",
    "        distance_matrix[i, j] = np.linalg.norm(\n",
    "            embeddings_np[switch_indices[i]] - embeddings_np[switch_indices[j]]\n",
    "        )\n",
    "\n",
    "# Find patient zero position in switch indices\n",
    "patient_zero_switch_pos = np.where(switch_indices == patient_zero_embedding_idx)[0][0]\n",
    "\n",
    "im = ax4.imshow(distance_matrix, cmap='viridis', interpolation='nearest')\n",
    "ax4.set_title('Switch-to-Switch Distance Matrix')\n",
    "ax4.set_xlabel('Switch Index')\n",
    "ax4.set_ylabel('Switch Index')\n",
    "\n",
    "# Highlight patient zero row and column\n",
    "ax4.axhline(y=patient_zero_switch_pos, color='red', linewidth=2, alpha=0.7)\n",
    "ax4.axvline(x=patient_zero_switch_pos, color='red', linewidth=2, alpha=0.7)\n",
    "ax4.text(0.02, 0.98, f'Patient Zero: Row/Col {patient_zero_switch_pos}', \n",
    "         transform=ax4.transAxes, color='red', fontweight='bold', \n",
    "         bbox=dict(boxstyle='round', facecolor='white', alpha=0.8))\n",
    "\n",
    "plt.colorbar(im, ax=ax4, label='Euclidean Distance')\n",
    "\n",
    "# 5. Dimensional Profile Comparison\n",
    "ax5 = plt.subplot(3, 3, 5)\n",
    "dim_indices = np.arange(embeddings_np.shape[1])\n",
    "ax5.plot(dim_indices, patient_zero_emb, 'r-', linewidth=2, marker='o', \n",
    "         markersize=3, label='Patient Zero', alpha=0.8)\n",
    "ax5.plot(dim_indices, same_type_mean, 'g--', linewidth=2, marker='s', \n",
    "         markersize=3, label='Switch Average', alpha=0.8)\n",
    "ax5.fill_between(dim_indices, \n",
    "                 same_type_mean - same_type_std, \n",
    "                 same_type_mean + same_type_std, \n",
    "                 alpha=0.3, color='green', label='±1 STD (Switches)')\n",
    "ax5.set_xlabel('Embedding Dimension')\n",
    "ax5.set_ylabel('Activation Value')\n",
    "ax5.set_title('Full Dimensional Profile Comparison')\n",
    "ax5.legend()\n",
    "ax5.grid(True, alpha=0.3)\n",
    "\n",
    "# 6. Z-Score Distribution\n",
    "ax6 = plt.subplot(3, 3, 6)\n",
    "z_scores = (patient_zero_emb - same_type_mean) / same_type_std\n",
    "colors = ['red' if abs(z) > 2 else 'orange' if abs(z) > 1 else 'green' for z in z_scores]\n",
    "bars = ax6.bar(dim_indices, z_scores, color=colors, alpha=0.7)\n",
    "ax6.axhline(y=2, color='red', linestyle='--', alpha=0.7, label='±2σ threshold')\n",
    "ax6.axhline(y=-2, color='red', linestyle='--', alpha=0.7)\n",
    "ax6.axhline(y=1, color='orange', linestyle='--', alpha=0.7, label='±1σ threshold')\n",
    "ax6.axhline(y=-1, color='orange', linestyle='--', alpha=0.7)\n",
    "ax6.set_xlabel('Embedding Dimension')\n",
    "ax6.set_ylabel('Z-Score vs Switch Mean')\n",
    "ax6.set_title('Patient Zero Z-Score Distribution')\n",
    "ax6.legend()\n",
    "ax6.grid(True, alpha=0.3)\n",
    "\n",
    "# 7. Box Plot Comparison for Top Deviating Dimensions\n",
    "ax7 = plt.subplot(3, 3, 7)\n",
    "top_5_dims = top_deviating_dims_all[:5]\n",
    "box_data = []\n",
    "patient_zero_values_top5 = []\n",
    "\n",
    "for dim in top_5_dims:\n",
    "    box_data.append(switch_embeddings[:, dim])\n",
    "    patient_zero_values_top5.append(patient_zero_emb[dim])\n",
    "\n",
    "bp = ax7.boxplot(box_data, labels=[f'D{dim}' for dim in top_5_dims], patch_artist=True)\n",
    "for patch in bp['boxes']:\n",
    "    patch.set_facecolor('lightblue')\n",
    "    patch.set_alpha(0.7)\n",
    "\n",
    "# Overlay patient zero values\n",
    "for i, (dim, val) in enumerate(zip(top_5_dims, patient_zero_values_top5)):\n",
    "    ax7.scatter(i+1, val, color='red', s=100, marker='*', zorder=10, \n",
    "               edgecolors='black', linewidth=1)\n",
    "\n",
    "ax7.set_title('Top 5 Deviating Dimensions\\nBox Plot Comparison')\n",
    "ax7.set_ylabel('Activation Value')\n",
    "ax7.grid(True, alpha=0.3)\n",
    "\n",
    "# Add legend\n",
    "red_star = plt.Line2D([0], [0], marker='*', color='w', markerfacecolor='red', \n",
    "                      markersize=10, markeredgecolor='black', label='Patient Zero')\n",
    "ax7.legend(handles=[red_star], loc='upper right')\n",
    "\n",
    "# 8. Cumulative Distance Distribution\n",
    "ax8 = plt.subplot(3, 3, 8)\n",
    "# Calculate distances from patient zero to all other switches\n",
    "distances_to_patient_zero = []\n",
    "for i, switch_idx in enumerate(switch_indices):\n",
    "    if switch_idx != patient_zero_embedding_idx:\n",
    "        dist = np.linalg.norm(embeddings_np[switch_idx] - patient_zero_emb)\n",
    "        distances_to_patient_zero.append(dist)\n",
    "\n",
    "# Calculate distances between all other switch pairs (excluding patient zero)\n",
    "other_switch_distances = []\n",
    "other_switch_indices = [idx for idx in switch_indices if idx != patient_zero_embedding_idx]\n",
    "for i in range(len(other_switch_indices)):\n",
    "    for j in range(i+1, len(other_switch_indices)):\n",
    "        dist = np.linalg.norm(embeddings_np[other_switch_indices[i]] - \n",
    "                             embeddings_np[other_switch_indices[j]])\n",
    "        other_switch_distances.append(dist)\n",
    "\n",
    "# Plot histograms\n",
    "ax8.hist(distances_to_patient_zero, bins=10, alpha=0.7, color='red', \n",
    "         label=f'Distances to Patient Zero\\n(mean: {np.mean(distances_to_patient_zero):.3f})', \n",
    "         density=True)\n",
    "ax8.hist(other_switch_distances, bins=10, alpha=0.7, color='blue', \n",
    "         label=f'Inter-Switch Distances\\n(mean: {np.mean(other_switch_distances):.3f})', \n",
    "         density=True)\n",
    "ax8.set_xlabel('Euclidean Distance')\n",
    "ax8.set_ylabel('Density')\n",
    "ax8.set_title('Distance Distribution Comparison')\n",
    "ax8.legend()\n",
    "ax8.grid(True, alpha=0.3)\n",
    "\n",
    "# 9. Summary Statistics Table\n",
    "ax9 = plt.subplot(3, 3, 9)\n",
    "ax9.axis('off')\n",
    "\n",
    "# Create summary statistics\n",
    "stats_data = [\n",
    "    ['Metric', 'Patient Zero', 'Switch Average', 'Deviation'],\n",
    "    ['Embedding Norm', f'{np.linalg.norm(patient_zero_emb):.3f}', \n",
    "     f'{np.linalg.norm(same_type_mean):.3f}', \n",
    "     f'{np.linalg.norm(patient_zero_emb) - np.linalg.norm(same_type_mean):.3f}'],\n",
    "    ['Mean Activation', f'{np.mean(patient_zero_emb):.3f}', \n",
    "     f'{np.mean(same_type_mean):.3f}', \n",
    "     f'{np.mean(patient_zero_emb) - np.mean(same_type_mean):.3f}'],\n",
    "    ['Max Activation', f'{np.max(patient_zero_emb):.3f}', \n",
    "     f'{np.max(same_type_mean):.3f}', \n",
    "     f'{np.max(patient_zero_emb) - np.max(same_type_mean):.3f}'],\n",
    "    ['Min Activation', f'{np.min(patient_zero_emb):.3f}', \n",
    "     f'{np.min(same_type_mean):.3f}', \n",
    "     f'{np.min(patient_zero_emb) - np.min(same_type_mean):.3f}'],\n",
    "    ['Std Deviation', f'{np.std(patient_zero_emb):.3f}', \n",
    "     f'{np.mean(same_type_std):.3f}', \n",
    "     f'{np.std(patient_zero_emb) - np.mean(same_type_std):.3f}'],\n",
    "    ['Avg |Z-Score|', f'{np.mean(np.abs(z_scores)):.3f}', '-', '-'],\n",
    "    ['Max |Z-Score|', f'{np.max(np.abs(z_scores)):.3f}', '-', '-'],\n",
    "    ['Dims > 2σ', f'{np.sum(np.abs(z_scores) > 2)}', '-', '-'],\n",
    "    ['Distance Rank', f'{patient_zero_dist_rank}/{len(switch_indices)}', '-', '-']\n",
    "]\n",
    "\n",
    "# Create table\n",
    "table = ax9.table(cellText=stats_data[1:], colLabels=stats_data[0], \n",
    "                  cellLoc='center', loc='center')\n",
    "table.auto_set_font_size(False)\n",
    "table.set_fontsize(8)\n",
    "table.scale(1, 2)\n",
    "\n",
    "# Color code the deviation column\n",
    "for i in range(1, len(stats_data)):\n",
    "    if i <= 6:  # Only for numeric comparisons\n",
    "        try:\n",
    "            dev_val = float(stats_data[i][3])\n",
    "            if abs(dev_val) > 0.1:\n",
    "                table[(i, 3)].set_facecolor('#ffcccc')  # Light red for high deviation\n",
    "            elif abs(dev_val) > 0.05:\n",
    "                table[(i, 3)].set_facecolor('#ffffcc')  # Light yellow for medium deviation\n",
    "        except ValueError:\n",
    "            pass\n",
    "\n",
    "ax9.set_title('Patient Zero Summary Statistics', pad=20)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Print detailed analysis\n",
    "print(f\"\\nDetailed Dimensional Analysis:\")\n",
    "print(f\"Patient Zero Embedding Index: {patient_zero_embedding_idx}\")\n",
    "print(f\"Patient Zero Device Type: {patient_zero_type}\")\n",
    "print(f\"Total Switch Devices: {len(switch_indices)}\")\n",
    "print(f\"\\nTop 10 Most Deviating Dimensions (vs Switch Average):\")\n",
    "for i, dim in enumerate(top_deviating_dims_same[:10]):\n",
    "    z_score = z_scores[dim]\n",
    "    deviation = patient_zero_emb[dim] - same_type_mean[dim]\n",
    "    print(f\"  {i+1:2d}. Dimension {dim:2d}: \"\n",
    "          f\"PZ={patient_zero_emb[dim]:7.3f}, \"\n",
    "          f\"Avg={same_type_mean[dim]:7.3f}, \"\n",
    "          f\"Dev={deviation:7.3f}, \"\n",
    "          f\"Z={z_score:6.2f}\")\n",
    "\n",
    "print(f\"\\nDistance Comparison:\")\n",
    "print(f\"  Average distance to other switches: {np.mean(distances_to_patient_zero):.3f}\")\n",
    "print(f\"  Average distance between other switches: {np.mean(other_switch_distances):.3f}\")\n",
    "print(f\"  Patient zero is {np.mean(distances_to_patient_zero)/np.mean(other_switch_distances):.2f}x more distant\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f15c8cb",
   "metadata": {},
   "source": [
    "# Heterogeneous Graph Attention Network (HGAT) Architecture Explanation\n",
    "\n",
    "## Overview\n",
    "The **Temporal Heterogeneous Graph Attention Network (T-HGAT)** in this notebook combines spatial heterogeneous graph processing with temporal sequence modeling for network failure analysis. It's designed to handle multiple device types (routers, switches, firewalls) and learn both their spatial relationships and temporal patterns.\n",
    "\n",
    "## Architecture Components\n",
    "\n",
    "### 1. **Input Layer Structure**\n",
    "```\n",
    "Input Features per Node:\n",
    "├── Numeric Features (2D): [CPU Usage, Memory Usage]\n",
    "├── Text Embeddings (384D): Sentence-BERT encoded status messages\n",
    "└── Total Input Dimension: 386D per node\n",
    "```\n",
    "\n",
    "### 2. **Heterogeneous Node Types**\n",
    "The model treats different device types as separate node types:\n",
    "- **Router Nodes**: Network routing devices\n",
    "- **Switch Nodes**: Network switching devices  \n",
    "- **Firewall Nodes**: Security filtering devices\n",
    "\n",
    "Each node type has its own feature space and learning parameters.\n",
    "\n",
    "### 3. **Spatial Processing Layer: HGTConv**\n",
    "The **Heterogeneous Graph Transformer (HGT)** layer handles different node and edge types:\n",
    "\n",
    "#### Key Features:\n",
    "- **Multi-head Attention**: 2 attention heads for learning different relationship patterns\n",
    "- **Type-specific Transformations**: Different weight matrices for each node type\n",
    "- **Heterogeneous Edges**: Handles connections between different device types\n",
    "- **Message Passing**: Aggregates information from neighboring nodes of potentially different types\n",
    "\n",
    "#### Mathematical Formulation:\n",
    "```\n",
    "For each node type τ and relation type φ:\n",
    "H^(l+1)[τ] = Aggregate({\n",
    "    Attention(Q^(l)[τ], K^(l)[φ], V^(l)[φ]) \n",
    "    for all φ connected to τ\n",
    "})\n",
    "```\n",
    "\n",
    "### 4. **Temporal Processing Layer: Type-specific GRU**\n",
    "Each device type has its own **Gated Recurrent Unit (GRU)**:\n",
    "\n",
    "#### Purpose:\n",
    "- **Temporal Sequence Learning**: Captures how device states evolve over time\n",
    "- **Type-specific Patterns**: Different device types may have different temporal behaviors\n",
    "- **Memory Retention**: GRU maintains information about past states\n",
    "\n",
    "#### Architecture:\n",
    "```\n",
    "For each device type τ:\n",
    "GRU_τ: (hidden_size=32, batch_first=True)\n",
    "Input: [batch_size, sequence_length, hidden_dim]\n",
    "Output: [batch_size, hidden_dim] (final timestep)\n",
    "```\n",
    "\n",
    "### 5. **Output Layers**\n",
    "\n",
    "#### Original Model:\n",
    "- **CPU Prediction**: Linear(32 → 1) for predicting next CPU usage\n",
    "\n",
    "#### Improved Multi-task Model:\n",
    "- **CPU Prediction**: Linear(32 → 1) for failure impact prediction\n",
    "- **Device Classification**: Linear(32 → 3) for device type classification\n",
    "- **Combined Loss**: CPU_loss + 0.5 × Device_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54ddbba1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================================================================\n",
    "# HGAT Architecture Visualization and Flow Diagram\n",
    "# ==============================================================================\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "from matplotlib.patches import FancyBboxPatch, Rectangle\n",
    "import numpy as np\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"HETEROGENEOUS GRAPH ATTENTION NETWORK (HGAT) ARCHITECTURE\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Create comprehensive architecture diagram\n",
    "fig = plt.figure(figsize=(18, 14))\n",
    "\n",
    "# Define colors for different components\n",
    "colors = {\n",
    "    'input': '#E8F4FD',\n",
    "    'spatial': '#B3E5FC', \n",
    "    'temporal': '#81C784',\n",
    "    'output': '#FFAB91',\n",
    "    'router': '#FF6B6B',\n",
    "    'switch': '#4ECDC4', \n",
    "    'firewall': '#45B7D1',\n",
    "    'attention': '#FFE082'\n",
    "}\n",
    "\n",
    "# Main architecture flow\n",
    "ax1 = plt.subplot(2, 2, (1, 2))\n",
    "ax1.set_xlim(0, 10)\n",
    "ax1.set_ylim(0, 12)\n",
    "ax1.axis('off')\n",
    "ax1.set_title('Temporal Heterogeneous Graph Attention Network Architecture', \n",
    "             fontsize=16, fontweight='bold', pad=20)\n",
    "\n",
    "# Draw the main components\n",
    "components = [\n",
    "    # Input Layer\n",
    "    {'name': 'Input Features\\n(Per Node)', 'pos': (1, 10), 'size': (1.5, 1.5), 'color': colors['input']},\n",
    "    {'name': 'CPU: 0.2\\nMem: 0.3\\nText: [384D]', 'pos': (0.5, 8.5), 'size': (1, 1), 'color': colors['input']},\n",
    "    {'name': 'Router\\nNodes', 'pos': (3, 10.5), 'size': (1, 0.8), 'color': colors['router']},\n",
    "    {'name': 'Switch\\nNodes', 'pos': (3, 9.5), 'size': (1, 0.8), 'color': colors['switch']},\n",
    "    {'name': 'Firewall\\nNodes', 'pos': (3, 8.5), 'size': (1, 0.8), 'color': colors['firewall']},\n",
    "    \n",
    "    # Spatial Processing\n",
    "    {'name': 'HGTConv Layer\\n(Multi-head Attention)', 'pos': (5.5, 9.5), 'size': (2, 1.5), 'color': colors['spatial']},\n",
    "    {'name': '2 Attention Heads\\nType-specific Weights', 'pos': (5.5, 8), 'size': (2, 0.8), 'color': colors['attention']},\n",
    "    \n",
    "    # Temporal Processing  \n",
    "    {'name': 'GRU_router', 'pos': (5, 6), 'size': (1.2, 0.8), 'color': colors['temporal']},\n",
    "    {'name': 'GRU_switch', 'pos': (6.5, 6), 'size': (1.2, 0.8), 'color': colors['temporal']},\n",
    "    {'name': 'GRU_firewall', 'pos': (8, 6), 'size': (1.2, 0.8), 'color': colors['temporal']},\n",
    "    \n",
    "    # Output\n",
    "    {'name': 'CPU Prediction\\nLinear(32→1)', 'pos': (5.5, 3.5), 'size': (1.8, 1), 'color': colors['output']},\n",
    "    {'name': 'Device Classification\\nLinear(32→3)', 'pos': (7.5, 3.5), 'size': (1.8, 1), 'color': colors['output']},\n",
    "    \n",
    "    # Final embedding\n",
    "    {'name': 'Node Embeddings\\n[N × 32D]', 'pos': (6.5, 1.5), 'size': (2, 1), 'color': colors['output']}\n",
    "]\n",
    "\n",
    "# Draw components\n",
    "for comp in components:\n",
    "    bbox = FancyBboxPatch(\n",
    "        comp['pos'], comp['size'][0], comp['size'][1],\n",
    "        boxstyle=\"round,pad=0.1\", \n",
    "        facecolor=comp['color'],\n",
    "        edgecolor='black',\n",
    "        linewidth=1.5\n",
    "    )\n",
    "    ax1.add_patch(bbox)\n",
    "    ax1.text(comp['pos'][0] + comp['size'][0]/2, comp['pos'][1] + comp['size'][1]/2, \n",
    "             comp['name'], ha='center', va='center', fontsize=9, fontweight='bold')\n",
    "\n",
    "# Draw arrows showing data flow\n",
    "arrows = [\n",
    "    # Input to node types\n",
    "    ((2.5, 10.2), (3, 10.2)),\n",
    "    ((2.5, 9.5), (3, 9.5)),\n",
    "    ((2.5, 8.8), (3, 8.8)),\n",
    "    \n",
    "    # Node types to HGT\n",
    "    ((4, 10.5), (5.5, 10.2)),\n",
    "    ((4, 9.5), (5.5, 9.5)),\n",
    "    ((4, 8.5), (5.5, 8.8)),\n",
    "    \n",
    "    # HGT to GRUs\n",
    "    ((6.5, 8), (5.5, 6.8)),\n",
    "    ((6.5, 8), (7, 6.8)),\n",
    "    ((6.5, 8), (8.5, 6.8)),\n",
    "    \n",
    "    # GRUs to outputs\n",
    "    ((6, 5.2), (6.2, 4.5)),\n",
    "    ((7.5, 5.2), (8.2, 4.5)),\n",
    "    \n",
    "    # To final embedding\n",
    "    ((6.5, 3.5), (7, 2.5)),\n",
    "    ((8.5, 3.5), (8, 2.5))\n",
    "]\n",
    "\n",
    "for start, end in arrows:\n",
    "    ax1.annotate('', xy=end, xytext=start,\n",
    "                arrowprops=dict(arrowstyle='->', lw=2, color='darkblue'))\n",
    "\n",
    "# Add temporal dimension indicator\n",
    "ax1.text(1, 6, 'Temporal\\nDimension\\n(T=3 timesteps)', ha='center', va='center',\n",
    "         fontsize=10, bbox=dict(boxstyle=\"round,pad=0.3\", facecolor='lightyellow', alpha=0.8))\n",
    "\n",
    "# Detailed HGT Attention Mechanism\n",
    "ax2 = plt.subplot(2, 2, 3)\n",
    "ax2.set_xlim(0, 8)\n",
    "ax2.set_ylim(0, 6)\n",
    "ax2.axis('off')\n",
    "ax2.set_title('HGT Attention Mechanism Detail', fontsize=14, fontweight='bold')\n",
    "\n",
    "# Draw attention computation\n",
    "attention_components = [\n",
    "    {'name': 'Query (Q)\\nRouter→Switch', 'pos': (0.5, 4.5), 'size': (1.5, 1), 'color': colors['attention']},\n",
    "    {'name': 'Key (K)\\nSwitch Features', 'pos': (2.5, 4.5), 'size': (1.5, 1), 'color': colors['attention']},\n",
    "    {'name': 'Value (V)\\nSwitch Features', 'pos': (4.5, 4.5), 'size': (1.5, 1), 'color': colors['attention']},\n",
    "    {'name': 'Attention\\nWeights', 'pos': (2.5, 2.5), 'size': (1.5, 1), 'color': colors['spatial']},\n",
    "    {'name': 'Weighted\\nMessage', 'pos': (5.5, 2.5), 'size': (1.5, 1), 'color': colors['spatial']},\n",
    "    {'name': 'Aggregated\\nEmbedding', 'pos': (3.5, 0.5), 'size': (1.5, 1), 'color': colors['output']}\n",
    "]\n",
    "\n",
    "for comp in attention_components:\n",
    "    bbox = FancyBboxPatch(\n",
    "        comp['pos'], comp['size'][0], comp['size'][1],\n",
    "        boxstyle=\"round,pad=0.1\", \n",
    "        facecolor=comp['color'],\n",
    "        edgecolor='black',\n",
    "        linewidth=1\n",
    "    )\n",
    "    ax2.add_patch(bbox)\n",
    "    ax2.text(comp['pos'][0] + comp['size'][0]/2, comp['pos'][1] + comp['size'][1]/2, \n",
    "             comp['name'], ha='center', va='center', fontsize=8, fontweight='bold')\n",
    "\n",
    "# Attention flow arrows\n",
    "attention_arrows = [\n",
    "    ((2, 4.5), (2.5, 3.5)),  # Q to attention\n",
    "    ((3.25, 4.5), (3.25, 3.5)),  # K to attention\n",
    "    ((5.25, 4.5), (5.25, 3.5)),  # V to weighted message\n",
    "    ((4, 2.5), (4.5, 1.5)),  # Attention + Message to final\n",
    "    ((5.5, 2.5), (4.5, 1.5))   # Weighted message to final\n",
    "]\n",
    "\n",
    "for start, end in attention_arrows:\n",
    "    ax2.annotate('', xy=end, xytext=start,\n",
    "                arrowprops=dict(arrowstyle='->', lw=1.5, color='darkred'))\n",
    "\n",
    "# Multi-task Learning Diagram\n",
    "ax3 = plt.subplot(2, 2, 4)\n",
    "ax3.set_xlim(0, 8)\n",
    "ax3.set_ylim(0, 6)\n",
    "ax3.axis('off')\n",
    "ax3.set_title('Multi-task Learning Objectives', fontsize=14, fontweight='bold')\n",
    "\n",
    "# Draw multi-task components\n",
    "multitask_components = [\n",
    "    {'name': 'Node Embedding\\n[32D]', 'pos': (3.5, 4.5), 'size': (1.5, 1), 'color': colors['temporal']},\n",
    "    {'name': 'CPU Prediction\\nTask', 'pos': (1.5, 2.5), 'size': (1.5, 1), 'color': colors['output']},\n",
    "    {'name': 'Device Type\\nClassification', 'pos': (5, 2.5), 'size': (1.5, 1), 'color': colors['output']},\n",
    "    {'name': 'MSE Loss\\n(Failure Impact)', 'pos': (1.5, 0.5), 'size': (1.5, 1), 'color': '#FFCDD2'},\n",
    "    {'name': 'CrossEntropy Loss\\n(Device Type)', 'pos': (5, 0.5), 'size': (1.5, 1), 'color': '#FFCDD2'},\n",
    "    {'name': 'Combined Loss\\nL = L_cpu + 0.5×L_device', 'pos': (3, 0.5), 'size': (2, 0.8), 'color': '#F8BBD9'}\n",
    "]\n",
    "\n",
    "for comp in multitask_components:\n",
    "    bbox = FancyBboxPatch(\n",
    "        comp['pos'], comp['size'][0], comp['size'][1],\n",
    "        boxstyle=\"round,pad=0.1\", \n",
    "        facecolor=comp['color'],\n",
    "        edgecolor='black',\n",
    "        linewidth=1\n",
    "    )\n",
    "    ax3.add_patch(bbox)\n",
    "    ax3.text(comp['pos'][0] + comp['size'][0]/2, comp['pos'][1] + comp['size'][1]/2, \n",
    "             comp['name'], ha='center', va='center', fontsize=8, fontweight='bold')\n",
    "\n",
    "# Multi-task arrows\n",
    "multitask_arrows = [\n",
    "    ((3.5, 4.5), (2.5, 3.5)),   # Embedding to CPU task\n",
    "    ((4.5, 4.5), (5.5, 3.5)),   # Embedding to device task\n",
    "    ((2.25, 2.5), (2.25, 1.5)), # CPU task to loss\n",
    "    ((5.75, 2.5), (5.75, 1.5)), # Device task to loss\n",
    "    ((2.25, 0.5), (3, 0.5)),    # Losses to combined\n",
    "    ((5.75, 0.5), (5, 0.5))\n",
    "]\n",
    "\n",
    "for start, end in multitask_arrows:\n",
    "    ax3.annotate('', xy=end, xytext=start,\n",
    "                arrowprops=dict(arrowstyle='->', lw=1.5, color='darkgreen'))\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Print detailed explanation\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"ARCHITECTURE COMPONENTS BREAKDOWN\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "print(\"\\n1. INPUT PROCESSING:\")\n",
    "print(f\"   • Numeric Features: 2D (CPU usage, Memory usage)\")\n",
    "print(f\"   • Text Embeddings: 384D (Sentence-BERT encoded status messages)\")\n",
    "print(f\"   • Total Input Dimension: 386D per node\")\n",
    "print(f\"   • Node Types: 3 (router, switch, firewall)\")\n",
    "\n",
    "print(\"\\n2. SPATIAL PROCESSING (HGTConv):\")\n",
    "print(f\"   • Input Channels: 386D\")\n",
    "print(f\"   • Hidden Channels: 32D\") \n",
    "print(f\"   • Attention Heads: 2\")\n",
    "print(f\"   • Heterogeneous Edge Types: Multiple (router-router, router-switch, etc.)\")\n",
    "print(\"   • Purpose: Learn spatial relationships between different device types\")\n",
    "\n",
    "print(\"\\n3. TEMPORAL PROCESSING (GRU):\")\n",
    "print(f\"   • Hidden Size: 32D\")\n",
    "print(f\"   • Sequence Length: 3 timesteps\")\n",
    "print(f\"   • Separate GRU per device type: 3 GRUs\")\n",
    "print(\"   • Purpose: Capture temporal evolution of device states\")\n",
    "\n",
    "print(\"\\n4. OUTPUT LAYERS:\")\n",
    "print(\"   Original Model:\")\n",
    "print(f\"     - CPU Prediction: Linear(32 → 1)\")\n",
    "print(\"   Improved Multi-task Model:\")\n",
    "print(f\"     - CPU Prediction: Linear(32 → 1)\")\n",
    "print(f\"     - Device Classification: Linear(32 → 3)\")\n",
    "\n",
    "print(\"\\n5. TRAINING OBJECTIVES:\")\n",
    "print(\"   Original Model:\")\n",
    "print(\"     - MSE Loss for CPU prediction\")\n",
    "print(\"   Improved Model:\")\n",
    "print(\"     - Combined Loss = MSE(CPU) + 0.5 × CrossEntropy(Device)\")\n",
    "print(\"     - Encourages device type separation in embeddings\")\n",
    "\n",
    "print(\"\\n6. KEY INNOVATIONS:\")\n",
    "print(\"   • Heterogeneous graph processing with different device types\")\n",
    "print(\"   • Temporal modeling with type-specific GRUs\") \n",
    "print(\"   • Multi-task learning for better representation learning\")\n",
    "print(\"   • Attention mechanism for learning device interactions\")\n",
    "\n",
    "print(\"\\n7. PERFORMANCE METRICS:\")\n",
    "print(f\"   • Original Model - Silhouette Score: 0.73\")\n",
    "print(f\"   • Improved Model - Silhouette Score: 0.85 (+16.5%)\")\n",
    "print(f\"   • Device Classification Accuracy: 100%\")\n",
    "print(f\"   • Adjusted Rand Index: 0.01 → 1.00 (perfect clustering)\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f487661c",
   "metadata": {},
   "source": [
    "## Mathematical Formulation\n",
    "\n",
    "### 1. **Heterogeneous Graph Transformer (HGT) Layer**\n",
    "\n",
    "The HGT layer processes heterogeneous graphs with multiple node and edge types. For each node type τ and edge type φ:\n",
    "\n",
    "#### **Attention Computation:**\n",
    "```\n",
    "For source node type τ_src and target node type τ_tgt:\n",
    "\n",
    "Q^τ_src = H^(l)[τ_src] × W^Q_τ_src    (Query matrix)\n",
    "K^τ_tgt = H^(l)[τ_tgt] × W^K_τ_tgt    (Key matrix)  \n",
    "V^τ_tgt = H^(l)[τ_tgt] × W^V_τ_tgt    (Value matrix)\n",
    "\n",
    "Attention(τ_src, τ_tgt) = softmax(Q^τ_src × K^τ_tgt^T / √d_k)\n",
    "```\n",
    "\n",
    "#### **Message Passing:**\n",
    "```\n",
    "Message_i = Σ_j∈N(i) Attention(τ_i, τ_j) × V^τ_j\n",
    "\n",
    "H^(l+1)[τ] = LayerNorm(H^(l)[τ] + Message_τ)\n",
    "```\n",
    "\n",
    "Where:\n",
    "- `H^(l)[τ]` = embeddings for node type τ at layer l\n",
    "- `W^Q_τ`, `W^K_τ`, `W^V_τ` = learnable type-specific weight matrices\n",
    "- `N(i)` = neighborhood of node i\n",
    "- `d_k` = dimension of key vectors\n",
    "\n",
    "### 2. **Temporal GRU Processing**\n",
    "\n",
    "For each device type τ, the GRU processes temporal sequences:\n",
    "\n",
    "#### **GRU Equations:**\n",
    "```\n",
    "r_t = σ(W_r × [h_{t-1}, x_t])         (Reset gate)\n",
    "z_t = σ(W_z × [h_{t-1}, x_t])         (Update gate)\n",
    "h̃_t = tanh(W_h × [r_t ⊙ h_{t-1}, x_t]) (Candidate state)\n",
    "h_t = (1 - z_t) ⊙ h_{t-1} + z_t ⊙ h̃_t (Hidden state)\n",
    "```\n",
    "\n",
    "Where:\n",
    "- `x_t` = spatial embedding at timestep t from HGT layer\n",
    "- `h_t` = hidden state at timestep t\n",
    "- `σ` = sigmoid function\n",
    "- `⊙` = element-wise multiplication\n",
    "\n",
    "### 3. **Multi-task Loss Function**\n",
    "\n",
    "#### **Combined Objective:**\n",
    "```\n",
    "L_total = L_CPU + λ × L_device\n",
    "\n",
    "L_CPU = MSE(ŷ_cpu, y_cpu) = (1/N) Σ(ŷ_cpu - y_cpu)²\n",
    "\n",
    "L_device = CrossEntropy(ŷ_device, y_device) \n",
    "         = -(1/N) Σ Σ y_device[i,c] × log(ŷ_device[i,c])\n",
    "\n",
    "Where λ = 0.5 (device task weight)\n",
    "```\n",
    "\n",
    "### 4. **Model Complexity Analysis**\n",
    "\n",
    "#### **Parameter Count:**\n",
    "- **HGT Layer**: O(|V| × d_h × h) where |V| = node types, d_h = hidden dim, h = heads\n",
    "- **GRU Layers**: O(|V| × 3 × d_h²) for 3 gates per device type  \n",
    "- **Output Layers**: O(d_h × (1 + |V|)) for CPU + device classification\n",
    "\n",
    "#### **Computational Complexity:**\n",
    "- **Spatial**: O(|E| × d_h) per timestep where |E| = number of edges\n",
    "- **Temporal**: O(T × |N| × d_h²) where T = sequence length, |N| = total nodes\n",
    "- **Total**: O(T × (|E| × d_h + |N| × d_h²))\n",
    "\n",
    "## Key Advantages of This Architecture\n",
    "\n",
    "### 1. **Heterogeneous Processing**\n",
    "- **Type-specific Parameters**: Different learnable weights for each device type\n",
    "- **Cross-type Interactions**: Can model router→switch, switch→firewall relationships\n",
    "- **Scalable**: Easy to add new device types without architectural changes\n",
    "\n",
    "### 2. **Temporal Modeling**\n",
    "- **Memory Retention**: GRU maintains information about past device states\n",
    "- **Type-specific Patterns**: Each device type learns its own temporal dynamics\n",
    "- **Failure Propagation**: Can track how failures spread through the network over time\n",
    "\n",
    "### 3. **Multi-task Learning Benefits**\n",
    "- **Better Representations**: Device classification forces embeddings to be type-discriminative\n",
    "- **Regularization**: Additional objective prevents overfitting to CPU prediction task\n",
    "- **Interpretability**: Clear separation between device types in embedding space\n",
    "\n",
    "### 4. **Attention Mechanism**\n",
    "- **Adaptive Weights**: Learns which connections are most important for each prediction\n",
    "- **Interpretable**: Attention weights show which devices influence each other most\n",
    "- **Dynamic**: Attention can change based on network state and failure conditions"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
